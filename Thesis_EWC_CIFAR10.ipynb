{"cells":[{"cell_type":"markdown","metadata":{"id":"VIY5TWRfCnTX"},"source":["# Permuted TensorFlow"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vYQRAKJSCPAx"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D\n","from tensorflow.keras.layers import MaxPooling2D\n","from tensorflow.keras.layers import Activation\n","from tensorflow.keras.layers import Flatten\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras import layers\n","from tensorflow.keras import backend as K\n","import numpy as np\n","from tqdm import tqdm\n","\n","\n","def evaluate(model, test_x, test_y):\n","    acc = tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy')\n","    for imgs, labels in zip(test_x, test_y):\n","        preds = model.predict_on_batch(np.array([imgs]))\n","        acc.update_state(labels, preds)\n","    return round(100*acc.result().numpy(), 2)\n","\n","\n","def permute_task(train, test):\n","    train_shape, test_shape = train.shape, test.shape\n","    train_flat, test_flat = train.reshape((-1, 3072)), test.reshape((-1, 3072))\n","    idx = np.arange(train_flat.shape[1])\n","    np.random.shuffle(idx)\n","    train_permuted, test_permuted = train_flat[:, idx], test_flat[:, idx]\n","    return (train_permuted.reshape(train_shape), test_permuted.reshape(test_shape))\n","\n","\n","class Train:\n","\n","    def __init__(self, optimizer, loss_fn, prior_weights=None, lambda_=0.1):\n","        self.optimizer = optimizer\n","        self.loss_fn = loss_fn\n","        self.prior_weights = prior_weights\n","        self.lambda_ = lambda_\n","\n","    def train(self, model, epochs, train_task, fisher_matrix=None, test_tasks=None):\n","        # empty list to collect per epoch test acc of each task\n","        if test_tasks:\n","            test_acc = [[] for _ in test_tasks]\n","        else:\n","            test_acc = None\n","        for epoch in tqdm(range(epochs)):\n","            for batch in train_task:\n","                X, y = batch\n","                with tf.GradientTape() as tape:\n","                    pred = model(X)\n","                    loss = self.loss_fn(y, pred)\n","                    # if to execute training with EWC\n","                    if fisher_matrix is not None:\n","                        loss += self.compute_penalty_loss(model, fisher_matrix)\n","                grads = tape.gradient(loss, model.trainable_variables)\n","                self.optimizer.apply_gradients(zip(grads, model.trainable_variables))\n","            # evaluate with the test set of task after each epoch\n","            if test_acc:\n","                for i in range(len(test_tasks)):\n","                    test_acc[i].append(evaluate(model, test_tasks[i][0], test_tasks[i][1]))\n","        print(test_acc)\n","        return test_acc\n","\n","    def compute_penalty_loss(self, model, fisher_matrix):\n","        penalty = 0.\n","        for u, v, w in zip(fisher_matrix, model.weights, self.prior_weights):\n","            penalty += tf.math.reduce_sum(u * tf.math.square(v - w))\n","        return 0.5 * self.lambda_ * penalty\n","\n","\n","class EWC:\n","\n","    def __init__(self, prior_model, data_samples, num_sample=30):\n","        self.prior_model = prior_model\n","        self.prior_weights = prior_model.weights\n","        self.num_sample = num_sample\n","        self.data_samples = data_samples\n","        self.fisher_matrix = self.compute_fisher()\n","\n","    def compute_fisher(self):\n","        weights = self.prior_weights\n","        fisher_accum = np.array([np.zeros(layer.numpy().shape) for layer in weights],\n","                           dtype=object\n","                          )\n","        for j in tqdm(range(self.num_sample)):\n","            idx = np.random.randint(self.data_samples.shape[0])\n","            with tf.GradientTape() as tape:\n","                logits = tf.nn.log_softmax(self.prior_model(np.array([self.data_samples[idx]])))\n","            grads = tape.gradient(logits, weights)\n","            for m in range(len(weights)):\n","                fisher_accum[m] += np.square(grads[m])\n","        fisher_accum /= self.num_sample\n","        return fisher_accum\n","\n","    def get_fisher(self):\n","        return self.fisher_matrix\n","\n","\n","from keras.models import Sequential\n","from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D\n","\n","class Convmodel:\n","    def __init__(self, input_shape=(32,32,3), hidden_layers_neuron_list=[200, 100, 50, 25, 12], num_classes=10):\n","        self.input_shape = input_shape\n","        self.num_classes = num_classes\n","        self.hidden_layers_neuron_list = hidden_layers_neuron_list\n","        self.model = self.create_cnn()\n","\n","    def create_cnn(self):\n","        model = Sequential()\n","\n","        # Convolutional layers\n","        model.add(Conv2D(32, (3, 3), activation='relu', input_shape=self.input_shape))\n","        model.add(MaxPooling2D((2, 2),padding='same'))\n","        model.add(Conv2D(64, (3, 3), activation='relu'))\n","        model.add(MaxPooling2D((2, 2),padding='same'))\n","        model.add(Conv2D(128, (3, 3), activation='relu'))\n","        model.add(MaxPooling2D((2, 2),padding='same'))\n","        model.add(Conv2D(256, (3, 3), activation='relu'))\n","        model.add(MaxPooling2D((2, 2),padding='same'))\n","\n","        # Flatten layer\n","        model.add(Flatten())\n","\n","        # Dense layers\n","        model.add(Dense(self.hidden_layers_neuron_list[0], activation='relu'))\n","        model.add(Dense(self.hidden_layers_neuron_list[1], activation='relu'))\n","        model.add(Dense(self.hidden_layers_neuron_list[2], activation='relu'))\n","        model.add(Dense(self.hidden_layers_neuron_list[3], activation='relu'))\n","        model.add(Dense(self.hidden_layers_neuron_list[4], activation='relu'))\n","\n","        # Output layer\n","        model.add(Dense(self.num_classes, activation='softmax'))\n","\n","        return model\n","\n","    def get_uncompiled_model(self):\n","      return self.model\n","\n","    def get_compiled_model(self, optimizer, loss_fn, metrics ):\n","      compiled_model = self.model\n","      compiled_model.compile(optimizer, loss_fn, metrics)\n","      return compiled_model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QS6fE1X9Cm5S"},"outputs":[],"source":["from tensorflow.keras.layers import Dense\n","from tensorflow.keras.datasets import cifar10\n","from tensorflow.keras.models import Sequential\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import numpy as np\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w8IzTq1nDQc3"},"outputs":[],"source":["epochs = 5\n","lambda_ = 0.01\n","lr = 0.0001\n","num_sample = 30\n","opt = tf.keras.optimizers.Adam(learning_rate=lr)\n","loss_fn=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6bsS90YdDT4-"},"outputs":[],"source":["(x_train_A, y_train_A), (x_test_A, y_test_A) = cifar10.load_data()\n","x_train_A = x_train_A.astype('float32')\n","x_test_A = x_test_A.astype('float32')\n","\n","train_A = tf.data.Dataset.from_tensor_slices((x_train_A, y_train_A)).shuffle(1000).batch(32)\n","test_A = (x_test_A, y_test_A)\n","\n","x_train_B, x_test_B = permute_task(x_train_A, x_test_A)\n","y_train_B, y_test_B = y_train_A, y_test_A\n","\n","train_B = tf.data.Dataset.from_tensor_slices((x_train_B, y_train_B)).shuffle(1000).batch(4)\n","test_B = (x_test_B, y_test_B)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":254},"executionInfo":{"elapsed":487,"status":"error","timestamp":1701016264387,"user":{"displayName":"Achyuth Kasyap","userId":"12117926900346930702"},"user_tz":-330},"id":"WguUhl3vDWMl","outputId":"af46e2c0-2f9e-44b0-9fba-cb0ac55a314d"},"outputs":[{"ename":"NameError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-dcfa7025bcb7>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConvmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrn_gd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_compiled_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'opt' is not defined"]}],"source":["mlp = Convmodel()\n","\n","trn_gd = Train(opt, loss_fn)\n","model = mlp.get_compiled_model(opt, loss_fn, ['accuracy'])\n","\n","acc_prior_A = trn_gd.train(model, epochs, train_A, test_tasks=[test_A])[0]\n","model.save('CIFAR10_A.h5')\n","print('[INFO] Task A Original (SGD): {}'.format(acc_prior_A[-1]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CpGutw0cDYdB"},"outputs":[],"source":["# construct the fisher matrix using samples from task A\n","ewc = EWC(model, x_train_A, num_sample=num_sample)\n","f_matrix = ewc.get_fisher()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VnJoBnEkDcH-"},"outputs":[],"source":["model_ewcB = mlp.get_compiled_model(opt, loss_fn, ['accuracy'])\n","model_ewcB.load_weights('CIFAR10_A.h5')\n","prior_weights = model_ewcB.get_weights()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1shw0uJ-DePt"},"outputs":[],"source":["trn = Train(opt, loss_fn, prior_weights=prior_weights, lambda_=lambda_)\n","acc_ewcA, acc_ewcB = trn.train(model_ewcB,\n","                     epochs,\n","                     train_B,\n","                     fisher_matrix=f_matrix,\n","                     test_tasks=[test_A, test_B]\n","                    )\n","\n","print('[INFO] Task A ACC. after training B with EWC: {}'.format(acc_ewcA[-1]))\n","print('[INFO] Task B ACC. after training B with EWC: {}'.format(acc_ewcB[-1]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xc9_mu4cDgg7"},"outputs":[],"source":["model_sgdB = mlp.get_compiled_model(opt, loss_fn, ['accuracy'])\n","model_sgdB.load_weights('CIFAR10_A.h5')\n","acc_sgdA, acc_sgdB = trn_gd.train(model_sgdB, epochs, train_B, test_tasks = [test_A, test_B])\n","\n","print('[INFO] Task A ACC. after training B with GD: {}'.format(acc_sgdA[-1]))\n","print('[INFO] Task B ACC. after training B with GD: {}'.format(acc_sgdB[-1]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BFFMJ3WpDi0K"},"outputs":[],"source":["x = 0\n","total_width, n = 0.1, 2\n","width = total_width / n\n","x = x - (total_width - width) / 2\n","plt.style.use('ggplot')\n","plt.bar(x, acc_ewcB[-1], width=width, label='EWC B', hatch='w/', ec='w')\n","plt.bar(x + width, acc_sgdB[-1], width=width, label='SGD B', hatch='w/', ec='w')\n","plt.bar(x + 3.5 * width, acc_prior_A[-1], width=width, label='Prior A', hatch='w/', ec='w')\n","plt.bar(x + 4.5 * width, acc_ewcA[-1], width=width, label='EWC A', hatch='w/', ec='w')\n","plt.bar(x + 5.5 * width, acc_sgdA[-1], width=width, label='SGD A', hatch='w/', ec='w')\n","plt.legend(facecolor='white', loc='lower left')\n","plt.xticks(np.array([0., 3.5 * width]), ('Task B', 'Task A'))\n","plt.title('Training task B with EWC Vs SGD after \\n task A had been trained to criterion')\n","plt.xlim(-0.15, 0.35)\n","plt.ylim(0., 105.)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2YPQYh42Dk6m"},"outputs":[],"source":["plt.plot(range(0, epochs*2, 1), (acc_prior_A + acc_sgdA), color='green', linestyle='dashed', label = \"SGD\")\n","plt.plot(range(0, epochs*2, 1), (acc_prior_A + acc_ewcA), color='red', linestyle='dashed', label = \"EWC\")\n","plt.plot(range(0, epochs, 1), (acc_prior_A), color='blue', label = \"Prior\")\n","#plt.axvline(x=9, linestyle='dashed', color='green')\n","plt.xticks(range(0, epochs*2, 50))\n","plt.title('Training task B with EWC Vs SGD after \\n task A had been trained to criterion')\n","plt.legend(facecolor='white')\n","plt.ylabel('Test accuracy A')\n","plt.xlabel('Epochs')"]},{"cell_type":"markdown","metadata":{"id":"IcPEfQw8GAbr"},"source":["# Permuted ONE ARCHITECTURE"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Id44uB13GF8m"},"outputs":[],"source":["import torch\n","torch.cuda.is_available()\n","import torch\n","import torch.nn as nn\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import keras"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":8660,"status":"ok","timestamp":1701762296017,"user":{"displayName":"Achyuth Kasyap","userId":"12117926900346930702"},"user_tz":-330},"id":"W6kurxTIGaMv","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e4a60eb6-2c45-4b7c-aed2-cbde152d2a8d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170498071/170498071 [==============================] - 3s 0us/step\n"]}],"source":["[(x_train, t_train), (x_test, t_test)] = keras.datasets.cifar10.load_data()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6KdEKyv5gB9D"},"outputs":[],"source":["x_train = np.transpose(x_train, (0, 3, 1, 2))\n","x_test = np.transpose(x_test, (0, 3, 1, 2))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W534fAcc_pVd"},"outputs":[],"source":["# Assuming x_train and x_test are lists or arrays\n","try:\n","    x_train = np.asarray(x_train, dtype=np.float32)\n","except ValueError as e:\n","    print(\"Error converting x_train to float32:\", e)\n","\n","try:\n","    x_test = np.asarray(x_test, dtype=np.float32)\n","except ValueError as e:\n","    print(\"Error converting x_test to float32:\", e)\n","\n","# Check the data type of elements in x_train and x_test\n","if x_train.dtype != np.float32:\n","    try:\n","        x_train = x_train.astype(np.float32)\n","    except ValueError as e:\n","        print(\"Error converting x_train to float32:\", e)\n","\n","if x_test.dtype != np.float32:\n","    try:\n","        x_test = x_test.astype(np.float32)\n","    except ValueError as e:\n","        print(\"Error converting x_test to float32:\", e)\n","\n","t_train=t_train.squeeze()\n","t_test=t_test.squeeze()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"30QHptDuBk-b"},"outputs":[],"source":["x_train = torch.tensor(x_train, dtype=torch.float32)\n","t_train = torch.tensor(t_train, dtype=torch.float32)\n","x_test = torch.tensor(x_test, dtype=torch.float32)\n","t_test = torch.tensor(t_test, dtype=torch.float32)\n","\n","x_train = np.asarray(x_train)\n","t_train = np.asarray(t_train)\n","x_test = np.asarray(x_test)\n","t_test = np.asarray(t_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1701762303565,"user":{"displayName":"Achyuth Kasyap","userId":"12117926900346930702"},"user_tz":-330},"id":"71Pkike4B5IX","outputId":"9979cad7-053c-42ea-edbf-17f040223d8d"},"outputs":[{"output_type":"stream","name":"stdout","text":["x_train dim and type:  (50000, 3, 32, 32) float32\n","t_train dim and type:  (50000,) float32\n","x_test dim and type:  (10000, 3, 32, 32) float32\n","t_test dim and type:  (10000,) float32\n"]}],"source":["print(\"x_train dim and type: \", x_train.shape, x_train.dtype)\n","print(\"t_train dim and type: \", t_train.shape, t_train.dtype)\n","print(\"x_test dim and type: \", x_test.shape, x_test.dtype)\n","print(\"t_test dim and type: \", t_test.shape, t_test.dtype)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EsEb5Jr8NIeQ"},"outputs":[],"source":["# switch to False to use CPU\n","use_cuda = True\n","\n","use_cuda = use_cuda and torch.cuda.is_available()\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\");\n","torch.manual_seed(1);\n","batch_size=256\n","m = nn.LogSoftmax(dim=1)\n","Loss = nn.MSELoss()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tC00fJG33aIr"},"outputs":[],"source":["from sklearn.metrics import precision_score, recall_score, f1_score\n","\n","import torch.nn.functional as F\n","\n","class ONEArchitecture(nn.Module):\n","    def __init__(self):\n","        super(ONEArchitecture, self).__init__()\n","\n","        # Convolutional layers\n","        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n","        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n","        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n","\n","        # Fully connected layers\n","        self.fc1 = nn.Linear(131072, 512)\n","        self.fc2 = nn.Linear(512, 256)\n","        self.fc3 = nn.Linear(256, 10)\n","\n","    def forward(self, x):\n","        x = F.relu(self.conv1(x))\n","        x = F.relu(self.conv2(x))\n","        x = F.relu(self.conv3(x))\n","\n","        # Flatten the tensor before passing it to fully connected layers\n","        x = x.view(-1, 131072)\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n","\n","\n","def permute_cifar10(cifar10, seed):\n","    \"\"\" Given the training set, permute pixels of each img the same way. \"\"\"\n","    np.random.seed(seed)\n","    print(\"starting permutation...\")\n","    h = w = 32\n","    perm_inds = list(range(h * w))\n","    np.random.shuffle(perm_inds)\n","\n","    perm_cifar10 = []\n","    for data_set in cifar10:\n","        num_img = data_set.shape[0]\n","        num_channels = data_set.shape[1]\n","\n","        # Reshape and permute pixels for each sample in the dataset\n","        reshaped_set = data_set.reshape((num_img, num_channels, -1))\n","        permuted_set = np.array([sample[:, perm_inds].reshape((num_channels, h, w)) for sample in reshaped_set])\n","        perm_cifar10.append(permuted_set)\n","\n","    print(\"done.\")\n","    return perm_cifar10\n","\n","def on_task_update(task_id, x_mem, t_mem):\n","\n","  model.train()\n","  optimizer.zero_grad()\n","\n","  # accumulating gradients\n","  for start in range(0, len(t_mem)-1, batch_size):\n","      end = start + batch_size\n","      x, y = torch.from_numpy(x_mem[start:end]), torch.from_numpy(t_mem[start:end]).long()\n","      x, y = x.to(device), y.to(device)\n","      output = model(x)\n","      y = nn.functional.one_hot(y)\n","      y = y.squeeze()\n","      output = output.float()\n","      y = y.float()\n","      loss = Loss(m(output), y)\n","      loss.backward()\n","\n","  fisher_dict[task_id] = {}\n","  optpar_dict[task_id] = {}\n","\n","  # gradients accumulated can be used to calculate fisher\n","  for name, param in model.named_parameters():\n","\n","    optpar_dict[task_id][name] = param.data.clone()\n","    fisher_dict[task_id][name] = param.grad.data.clone().pow(2)\n","\n","def train_ewc(model, device, task_id, x_train, t_train, optimizer, epoch):\n","    model.train()\n","\n","    for start in range(0, len(t_train)-1, batch_size):\n","        end = start + batch_size\n","        x, y = torch.from_numpy(x_train[start:end]), torch.from_numpy(t_train[start:end]).long()\n","        x, y = x.to(device), y.to(device)\n","\n","        optimizer.zero_grad()\n","\n","        output = model(x)\n","        y = nn.functional.one_hot(y)\n","        y = y.squeeze()\n","        output = output.float()\n","        y = y.float()\n","        loss = F.cross_entropy(output, y)\n","\n","        ### magic here! :-)\n","        for task in range(task_id):\n","            for name, param in model.named_parameters():\n","                fisher = fisher_dict[task][name]\n","                optpar = optpar_dict[task][name]\n","                loss += (fisher * (optpar - param).pow(2)).sum() * ewc_lambda\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","    # After each epoch, evaluate and print metrics\n","    train_metrics = evaluate_metrics(model, device, x_train, t_train)\n","    # print(f'Train Epoch: {epoch}\\tLoss: {loss.item():.6f}\\tPrecision: {train_metrics[\"precision\"]:.4f}\\tRecall: {train_metrics[\"recall\"]:.4f}\\tF1 Score: {train_metrics[\"f1\"]:.4f}')\n","\n","def evaluate_metrics(model, device, x_data, t_data):\n","    model.eval()\n","    all_preds = []\n","    all_labels = []\n","\n","    for start in range(0, len(t_data)-1, batch_size):\n","        end = start + batch_size\n","        with torch.no_grad():\n","            x, y = torch.from_numpy(x_data[start:end]), torch.from_numpy(t_data[start:end]).long()\n","            x, y = x.to(device), y.to(device)\n","            output = model(x)\n","\n","            # Convert predictions to numpy arrays\n","            preds = output.argmax(dim=1).cpu().numpy()\n","            labels = y.cpu().numpy()\n","\n","            all_preds.extend(preds)\n","            all_labels.extend(labels)\n","\n","    # Calculate metrics\n","    precision = precision_score(all_labels, all_preds, average='weighted')\n","    recall = recall_score(all_labels, all_preds, average='weighted')\n","    f1 = f1_score(all_labels, all_preds, average='weighted')\n","\n","    return {'precision': precision, 'recall': recall, 'f1': f1}\n","\n","def train(model, device, x_train, t_train, optimizer, epoch):\n","    model.train()\n","\n","    for start in range(0, len(t_train)-1, batch_size):\n","      end = start + batch_size\n","      x, y = torch.from_numpy(x_train[start:end]), torch.from_numpy(t_train[start:end]).long()\n","      x, y = x.to(device), y.to(device)\n","\n","      optimizer.zero_grad()\n","\n","      output = model(x)\n","      y = nn.functional.one_hot(y)\n","      y = y.squeeze()\n","      output = output.float()\n","      y = y.float()\n","      loss = Loss(output, y)\n","      loss.backward()\n","      optimizer.step()\n","      #print(loss.item())\n","    print('Train Epoch: {} \\tLoss: {:.6f}'.format(epoch, loss.item()))\n","\n","def test(model, device, x_test, t_test):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    all_preds = []\n","    all_labels = []\n","\n","    for start in range(0, len(t_test)-1, batch_size):\n","        end = start + batch_size\n","        with torch.no_grad():\n","            x, y = torch.from_numpy(x_test[start:end]), torch.from_numpy(t_test[start:end]).long()\n","            x, y = x.to(device), y.to(device)\n","            output = model(x)\n","            test_loss += F.cross_entropy(output, y).item()  # sum up batch loss\n","            pred = output.max(1, keepdim=True)[1]  # get the index of the max logit\n","            correct += pred.eq(y.view_as(pred)).sum().item()\n","\n","            # Convert predictions to numpy arrays\n","            preds = pred.cpu().numpy()\n","            labels = y.cpu().numpy()\n","\n","            all_preds.extend(preds)\n","            all_labels.extend(labels)\n","\n","    test_loss /= len(t_test)\n","\n","    # Calculate metrics\n","    precision = precision_score(all_labels, all_preds, average='weighted')\n","    recall = recall_score(all_labels, all_preds, average='weighted')\n","    f1 = f1_score(all_labels, all_preds, average='weighted')\n","\n","    print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n","        test_loss, correct, len(t_test), 100. * correct / len(t_test)))\n","    print('Precision: {:.4f}, Recall: {:.4f}, F1 Score: {:.4f}\\n'.format(precision, recall, f1))\n","\n","    return 100. * correct / len(t_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27552,"status":"ok","timestamp":1701762335269,"user":{"displayName":"Achyuth Kasyap","userId":"12117926900346930702"},"user_tz":-330},"id":"TAExtbA9OGEi","outputId":"a0ff7d0c-9ad0-4ca2-f6d5-63cc7ac19515"},"outputs":[{"output_type":"stream","name":"stdout","text":["starting permutation...\n","done.\n","starting permutation...\n","done.\n"]}],"source":["# task 1\n","task_1 = [(x_train, t_train), (x_test, t_test)]\n","\n","# task 2\n","x_train2, x_test2 = permute_cifar10([x_train, x_test], 1)\n","task_2 = [(x_train2, t_train), (x_test2, t_test)]\n","\n","# task 3\n","x_train3, x_test3 = permute_cifar10([x_train, x_test], 2)\n","task_3 = [(x_train3, t_train), (x_test3, t_test)]\n","\n","# task list\n","tasks = [task_1, task_2, task_3]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ovQDFGd-OJgc"},"outputs":[],"source":["model = ONEArchitecture().to(device)\n","optimizer = optim.Adam(model.parameters(), lr=0.0001)\n","fisher_dict = {}\n","optpar_dict = {}\n","ewc_lambda = 0.5"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":880,"referenced_widgets":["89b0a362c70b48609fd5247dc12f2ad6","f31b6dd2d77a4d839173850cdb0dfb37","b55a1cf4d7cc49aeb778326a08f41073","ed846d1c4d04490b8ae344feff9cf187","59ffdb2397814f60bcbe06b4f0f74f20","e4c656a7732849b592bb77c48ebaf7d5","3e1cf61adbfd43ea941774a2e69f5aaa","c46bfa62e4b843b38c9abf10566660d8","2ddd9b64bef5471291ea8db8ae0bfe00","31be061d965443e0a0df01d0c46afdf4","840c63f630ed45bea8ea14587a947cd1","29efc36137844aa1aefcf9eff5f983a7","56c4bb4ee51946faa079c126a5541cfd","0611a6128cda42bcb6fb19e64a8bb8b2","9a22ee840a6a4b33af1c5862c3dc9c7e","1b890a0caef54e659a3ad55a02eac7f2","31abfa8522db4c52b16e4b68f5c83f6a","81a70ed088ad47938fd473c904cd00dc","759beef2a79a43c4b2caea80a80c5075","21d3e3ac241d4ae6bdc755394b2d330f","97e85e11592b44bb9dce82a297fb1662","225a020f261a4a10a5851491354535a8","3372cbc55848450397786a4d23c34902","020f431ced0046a0b8612e48c362b99b","bd5b606a15294392a361638084dddca4","a2906b32daa3422eaf23a86002a0eeb3","41a0047eca6045d2b117e8171fff30aa","19121d4e4e804729bde42011f89a8381","74ec4340ff7148e3a0c29939215c3ed7","3d0b77884cde4d3093be535cd1873a94","1552fd26b8864ab884e7b0a01473b12d","da6755aa49a242e2ada2637c75757001","0d865d4009fb44e9b5f1d224dd7272d8"]},"id":"nDsxtadF4bNl","executionInfo":{"status":"ok","timestamp":1701763560135,"user_tz":-330,"elapsed":1196898,"user":{"displayName":"Achyuth Kasyap","userId":"12117926900346930702"}},"outputId":"cd0d6e45-2ef2-45a1-ddbe-d8accdd81be2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Training on task:  0\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/15 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89b0a362c70b48609fd5247dc12f2ad6"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Testing on task:  0\n","Test set: Average loss: 0.0079, Accuracy: 6469/10000 (65%)\n","Precision: 0.6464, Recall: 0.6469, F1 Score: 0.6445\n","\n","Testing on task:  1\n","Test set: Average loss: 0.0946, Accuracy: 1163/10000 (12%)\n","Precision: 0.1688, Recall: 0.1163, F1 Score: 0.0517\n","\n","Testing on task:  2\n","Test set: Average loss: 0.0926, Accuracy: 1246/10000 (12%)\n","Precision: 0.1347, Recall: 0.1246, F1 Score: 0.0599\n","\n","Avg acc:  29.593333333333334\n","Training on task:  1\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/15 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29efc36137844aa1aefcf9eff5f983a7"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Testing on task:  0\n","Test set: Average loss: 0.0088, Accuracy: 2767/10000 (28%)\n","Precision: 0.3324, Recall: 0.2767, F1 Score: 0.2642\n","\n","Testing on task:  1\n","Test set: Average loss: 0.0058, Accuracy: 4915/10000 (49%)\n","Precision: 0.5013, Recall: 0.4915, F1 Score: 0.4856\n","\n","Testing on task:  2\n","Test set: Average loss: 0.0100, Accuracy: 1985/10000 (20%)\n","Precision: 0.1788, Recall: 0.1985, F1 Score: 0.1653\n","\n","Avg acc:  32.22333333333333\n","Training on task:  2\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/15 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3372cbc55848450397786a4d23c34902"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Testing on task:  0\n","Test set: Average loss: 0.0088, Accuracy: 2730/10000 (27%)\n","Precision: 0.3449, Recall: 0.2730, F1 Score: 0.2590\n","\n","Testing on task:  1\n","Test set: Average loss: 0.0061, Accuracy: 4637/10000 (46%)\n","Precision: 0.4924, Recall: 0.4637, F1 Score: 0.4596\n","\n","Testing on task:  2\n","Test set: Average loss: 0.0072, Accuracy: 3605/10000 (36%)\n","Precision: 0.3793, Recall: 0.3605, F1 Score: 0.3549\n","\n","Avg acc:  36.57333333333333\n"]}],"source":["import warnings\n","warnings.filterwarnings('ignore')\n","from tqdm.auto import tqdm\n","\n","ewc_accs = []\n","for id, task in enumerate(tasks):\n","  avg_acc = 0\n","  print(\"Training on task: \", id)\n","\n","  (x_train, t_train), _ = task\n","\n","  for epoch in tqdm(range(1, 16)):\n","    train_ewc(model, device, id, x_train, t_train, optimizer, epoch)\n","  on_task_update(id, x_train, t_train)\n","\n","  for id_test, task in enumerate(tasks):\n","    print(\"Testing on task: \", id_test)\n","    _, (x_test, t_test) = task\n","    acc = test(model, device, x_test, t_test)\n","    avg_acc = avg_acc + acc\n","\n","  print(\"Avg acc: \", avg_acc / 3)\n","  ewc_accs.append(avg_acc / 3)"]},{"cell_type":"markdown","metadata":{"id":"o5jq2QpZpb_v"},"source":["# Permuted MobileNET"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lO55yEjXpeT-"},"outputs":[],"source":["import torch\n","torch.cuda.is_available()\n","import torch\n","import torch.nn as nn\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import keras"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14122,"status":"ok","timestamp":1701755321633,"user":{"displayName":"Achyuth Kasyap","userId":"12117926900346930702"},"user_tz":-330},"id":"1MGZHrpgpj3q","outputId":"9665f1fd-579d-43d1-e463-5dc5d59cf3da"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170498071/170498071 [==============================] - 11s 0us/step\n"]}],"source":["[(x_train, t_train), (x_test, t_test)] = keras.datasets.cifar10.load_data()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pCAsJ78bplgD"},"outputs":[],"source":["x_train = np.transpose(x_train, (0, 3, 1, 2))\n","x_test = np.transpose(x_test, (0, 3, 1, 2))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xw4J1y79pm6r"},"outputs":[],"source":["# Assuming x_train and x_test are lists or arrays\n","try:\n","    x_train = np.asarray(x_train, dtype=np.float32)\n","except ValueError as e:\n","    print(\"Error converting x_train to float32:\", e)\n","\n","try:\n","    x_test = np.asarray(x_test, dtype=np.float32)\n","except ValueError as e:\n","    print(\"Error converting x_test to float32:\", e)\n","\n","# Check the data type of elements in x_train and x_test\n","if x_train.dtype != np.float32:\n","    try:\n","        x_train = x_train.astype(np.float32)\n","    except ValueError as e:\n","        print(\"Error converting x_train to float32:\", e)\n","\n","if x_test.dtype != np.float32:\n","    try:\n","        x_test = x_test.astype(np.float32)\n","    except ValueError as e:\n","        print(\"Error converting x_test to float32:\", e)\n","\n","t_train=t_train.squeeze()\n","t_test=t_test.squeeze()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yUApax15poPb"},"outputs":[],"source":["x_train = torch.tensor(x_train, dtype=torch.float32)\n","t_train = torch.tensor(t_train, dtype=torch.float32)\n","x_test = torch.tensor(x_test, dtype=torch.float32)\n","t_test = torch.tensor(t_test, dtype=torch.float32)\n","\n","x_train = np.asarray(x_train)\n","t_train = np.asarray(t_train)\n","x_test = np.asarray(x_test)\n","t_test = np.asarray(t_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1701755322212,"user":{"displayName":"Achyuth Kasyap","userId":"12117926900346930702"},"user_tz":-330},"id":"powkgKp4ppfL","outputId":"b240fd67-e99f-42ee-e758-14d20f6dad25"},"outputs":[{"name":"stdout","output_type":"stream","text":["x_train dim and type:  (50000, 3, 32, 32) float32\n","t_train dim and type:  (50000,) float32\n","x_test dim and type:  (10000, 3, 32, 32) float32\n","t_test dim and type:  (10000,) float32\n"]}],"source":["print(\"x_train dim and type: \", x_train.shape, x_train.dtype)\n","print(\"t_train dim and type: \", t_train.shape, t_train.dtype)\n","print(\"x_test dim and type: \", x_test.shape, x_test.dtype)\n","print(\"t_test dim and type: \", t_test.shape, t_test.dtype)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JYqS8IZ2pq0G"},"outputs":[],"source":["# switch to False to use CPU\n","use_cuda = True\n","\n","use_cuda = use_cuda and torch.cuda.is_available()\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\");\n","torch.manual_seed(1);\n","batch_size=256\n","m = nn.LogSoftmax(dim=1)\n","Loss = nn.MSELoss()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fZV37sQXpsQ3"},"outputs":[],"source":["class DepthwiseSeparableConv(nn.Module):\n","    def __init__(self, in_channels, out_channels, stride):\n","        super(DepthwiseSeparableConv, self).__init__()\n","        self.depthwise = nn.Conv2d(in_channels, in_channels, kernel_size=3, stride=1, padding=1, groups=in_channels)\n","        self.pointwise = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0)\n","\n","    def forward(self, x):\n","        x = self.depthwise(x)\n","        x = self.pointwise(x)\n","        return x\n","\n","\n","class MobileNetV1(nn.Module):\n","    def __init__(self, num_classes=10):\n","        super(MobileNetV1, self).__init__()\n","        self.model = nn.Sequential(\n","            nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1),\n","            nn.ReLU(inplace=True),\n","            DepthwiseSeparableConv(32, 64, 1),\n","            DepthwiseSeparableConv(64, 128, 2),\n","            DepthwiseSeparableConv(128, 128, 1),\n","            DepthwiseSeparableConv(128, 256, 2),\n","            DepthwiseSeparableConv(256, 256, 1),\n","            DepthwiseSeparableConv(256, 512, 2),\n","            # Repeat the following block 5 times for depth\n","            DepthwiseSeparableConv(512, 512, 1),\n","            DepthwiseSeparableConv(512, 512, 1),\n","            DepthwiseSeparableConv(512, 512, 1),\n","            DepthwiseSeparableConv(512, 512, 1),\n","            DepthwiseSeparableConv(512, 512, 1),\n","            # End of repeating block\n","            DepthwiseSeparableConv(512, 1024, 2),\n","            DepthwiseSeparableConv(1024, 1024, 1),\n","            nn.AdaptiveAvgPool2d(1)\n","        )\n","        self.fc = nn.Linear(1024, 10)\n","\n","    def forward(self, x):\n","        x = self.model(x)\n","        x = x.view(x.size(0), -1)\n","        x = self.fc(x)\n","        return x\n","\n","model = MobileNetV1()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eHFak38ep24W"},"outputs":[],"source":["def permute_cifar10(cifar10, seed):\n","    \"\"\" Given the training set, permute pixels of each img the same way. \"\"\"\n","    np.random.seed(seed)\n","    print(\"starting permutation...\")\n","    h = w = 32\n","    perm_inds = list(range(h * w))\n","    np.random.shuffle(perm_inds)\n","\n","    perm_cifar10 = []\n","    for data_set in cifar10:\n","        num_img = data_set.shape[0]\n","        num_channels = data_set.shape[1]\n","\n","        # Reshape and permute pixels for each sample in the dataset\n","        reshaped_set = data_set.reshape((num_img, num_channels, -1))\n","        permuted_set = np.array([sample[:, perm_inds].reshape((num_channels, h, w)) for sample in reshaped_set])\n","        perm_cifar10.append(permuted_set)\n","\n","    print(\"done.\")\n","    return perm_cifar10\n","\n","def on_task_update(task_id, x_mem, t_mem):\n","\n","  model.train()\n","  optimizer.zero_grad()\n","\n","  # accumulating gradients\n","  for start in range(0, len(t_mem)-1, batch_size):\n","      end = start + batch_size\n","      x, y = torch.from_numpy(x_mem[start:end]), torch.from_numpy(t_mem[start:end]).long()\n","      x, y = x.to(device), y.to(device)\n","      output = model(x)\n","      y = nn.functional.one_hot(y)\n","      y = y.squeeze()\n","      output = output.float()\n","      y = y.float()\n","      loss = Loss(m(output), y)\n","      loss.backward()\n","\n","  fisher_dict[task_id] = {}\n","  optpar_dict[task_id] = {}\n","\n","  # gradients accumulated can be used to calculate fisher\n","  for name, param in model.named_parameters():\n","\n","    optpar_dict[task_id][name] = param.data.clone()\n","    fisher_dict[task_id][name] = param.grad.data.clone().pow(2)\n","\n","def train_ewc(model, device, task_id, x_train, t_train, optimizer, epoch):\n","    model.train()\n","\n","    for start in range(0, len(t_train)-1, batch_size):\n","        end = start + batch_size\n","        x, y = torch.from_numpy(x_train[start:end]), torch.from_numpy(t_train[start:end]).long()\n","        x, y = x.to(device), y.to(device)\n","\n","        optimizer.zero_grad()\n","\n","        output = model(x)\n","        y = nn.functional.one_hot(y)\n","        y = y.squeeze()\n","        output = output.float()\n","        y = y.float()\n","        loss = F.cross_entropy(output, y)\n","\n","        ### magic here! :-)\n","        for task in range(task_id):\n","            for name, param in model.named_parameters():\n","                fisher = fisher_dict[task][name]\n","                optpar = optpar_dict[task][name]\n","                loss += (fisher * (optpar - param).pow(2)).sum() * ewc_lambda\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","    # After each epoch, evaluate and print metrics\n","    train_metrics = evaluate_metrics(model, device, x_train, t_train)\n","    # print(f'Train Epoch: {epoch}\\tLoss: {loss.item():.6f}\\tPrecision: {train_metrics[\"precision\"]:.4f}\\tRecall: {train_metrics[\"recall\"]:.4f}\\tF1 Score: {train_metrics[\"f1\"]:.4f}')\n","\n","def evaluate_metrics(model, device, x_data, t_data):\n","    model.eval()\n","    all_preds = []\n","    all_labels = []\n","\n","    for start in range(0, len(t_data)-1, batch_size):\n","        end = start + batch_size\n","        with torch.no_grad():\n","            x, y = torch.from_numpy(x_data[start:end]), torch.from_numpy(t_data[start:end]).long()\n","            x, y = x.to(device), y.to(device)\n","            output = model(x)\n","\n","            # Convert predictions to numpy arrays\n","            preds = output.argmax(dim=1).cpu().numpy()\n","            labels = y.cpu().numpy()\n","\n","            all_preds.extend(preds)\n","            all_labels.extend(labels)\n","\n","    # Calculate metrics\n","    precision = precision_score(all_labels, all_preds, average='weighted')\n","    recall = recall_score(all_labels, all_preds, average='weighted')\n","    f1 = f1_score(all_labels, all_preds, average='weighted')\n","\n","    return {'precision': precision, 'recall': recall, 'f1': f1}\n","\n","def train(model, device, x_train, t_train, optimizer, epoch):\n","    model.train()\n","\n","    for start in range(0, len(t_train)-1, batch_size):\n","      end = start + batch_size\n","      x, y = torch.from_numpy(x_train[start:end]), torch.from_numpy(t_train[start:end]).long()\n","      x, y = x.to(device), y.to(device)\n","\n","      optimizer.zero_grad()\n","\n","      output = model(x)\n","      y = nn.functional.one_hot(y)\n","      y = y.squeeze()\n","      output = output.float()\n","      y = y.float()\n","      loss = Loss(output, y)\n","      loss.backward()\n","      optimizer.step()\n","      #print(loss.item())\n","    print('Train Epoch: {} \\tLoss: {:.6f}'.format(epoch, loss.item()))\n","\n","def test(model, device, x_test, t_test):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    all_preds = []\n","    all_labels = []\n","\n","    for start in range(0, len(t_test)-1, batch_size):\n","        end = start + batch_size\n","        with torch.no_grad():\n","            x, y = torch.from_numpy(x_test[start:end]), torch.from_numpy(t_test[start:end]).long()\n","            x, y = x.to(device), y.to(device)\n","            output = model(x)\n","            test_loss += F.cross_entropy(output, y).item()  # sum up batch loss\n","            pred = output.max(1, keepdim=True)[1]  # get the index of the max logit\n","            correct += pred.eq(y.view_as(pred)).sum().item()\n","\n","            # Convert predictions to numpy arrays\n","            preds = pred.cpu().numpy()\n","            labels = y.cpu().numpy()\n","\n","            all_preds.extend(preds)\n","            all_labels.extend(labels)\n","\n","    test_loss /= len(t_test)\n","\n","    # Calculate metrics\n","    precision = precision_score(all_labels, all_preds, average='weighted')\n","    recall = recall_score(all_labels, all_preds, average='weighted')\n","    f1 = f1_score(all_labels, all_preds, average='weighted')\n","\n","    print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n","        test_loss, correct, len(t_test), 100. * correct / len(t_test)))\n","    print('Precision: {:.4f}, Recall: {:.4f}, F1 Score: {:.4f}\\n'.format(precision, recall, f1))\n","\n","    return 100. * correct / len(t_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18021,"status":"ok","timestamp":1701755340229,"user":{"displayName":"Achyuth Kasyap","userId":"12117926900346930702"},"user_tz":-330},"id":"2Io5KwLSp3Uh","outputId":"acdac652-bd4b-47e2-d44f-d71b2f7e7b84"},"outputs":[{"name":"stdout","output_type":"stream","text":["starting permutation...\n","done.\n","starting permutation...\n","done.\n"]}],"source":["# task 1\n","task_1 = [(x_train, t_train), (x_test, t_test)]\n","\n","# task 2\n","x_train2, x_test2 = permute_cifar10([x_train, x_test], 1)\n","task_2 = [(x_train2, t_train), (x_test2, t_test)]\n","\n","# task 3\n","x_train3, x_test3 = permute_cifar10([x_train, x_test], 2)\n","task_3 = [(x_train3, t_train), (x_test3, t_test)]\n","\n","# task list\n","tasks = [task_1, task_2, task_3]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OTEcrtjQp4sw"},"outputs":[],"source":["optimizer = optim.Adam(model.parameters(), lr=0.0001)\n","fisher_dict = {}\n","optpar_dict = {}\n","ewc_lambda = 0.5"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bP2do_6ap66M","outputId":"4bfd0ec5-eeef-4e30-f0ab-98e4fbdba82b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training on task:  0\n"]}],"source":["import warnings\n","warnings.filterwarnings('ignore')\n","from sklearn.metrics import precision_score, recall_score, f1_score\n","import torch.nn.functional as F\n","\n","ewc_accs = []\n","for id, task in enumerate(tasks):\n","  avg_acc = 0\n","  print(\"Training on task: \", id)\n","\n","  (x_train, t_train), _ = task\n","\n","  for epoch in range(1, 16):\n","    train_ewc(model, device, id, x_train, t_train, optimizer, epoch)\n","  on_task_update(id, x_train, t_train)\n","\n","  for id_test, task in enumerate(tasks):\n","    print(\"Testing on task: \", id_test)\n","    _, (x_test, t_test) = task\n","    acc = test(model, device, x_test, t_test)\n","    avg_acc = avg_acc + acc\n","\n","  print(\"Avg acc: \", avg_acc / 3)\n","  ewc_accs.append(avg_acc / 3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gBYB4QIh0mkB"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[],"collapsed_sections":["VIY5TWRfCnTX","o5jq2QpZpb_v"],"gpuType":"T4","authorship_tag":"ABX9TyPPssID5sIMwuwxVOmGGyjW"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"89b0a362c70b48609fd5247dc12f2ad6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f31b6dd2d77a4d839173850cdb0dfb37","IPY_MODEL_b55a1cf4d7cc49aeb778326a08f41073","IPY_MODEL_ed846d1c4d04490b8ae344feff9cf187"],"layout":"IPY_MODEL_59ffdb2397814f60bcbe06b4f0f74f20"}},"f31b6dd2d77a4d839173850cdb0dfb37":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e4c656a7732849b592bb77c48ebaf7d5","placeholder":"​","style":"IPY_MODEL_3e1cf61adbfd43ea941774a2e69f5aaa","value":"100%"}},"b55a1cf4d7cc49aeb778326a08f41073":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c46bfa62e4b843b38c9abf10566660d8","max":15,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2ddd9b64bef5471291ea8db8ae0bfe00","value":15}},"ed846d1c4d04490b8ae344feff9cf187":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_31be061d965443e0a0df01d0c46afdf4","placeholder":"​","style":"IPY_MODEL_840c63f630ed45bea8ea14587a947cd1","value":" 15/15 [05:15&lt;00:00, 21.05s/it]"}},"59ffdb2397814f60bcbe06b4f0f74f20":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e4c656a7732849b592bb77c48ebaf7d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e1cf61adbfd43ea941774a2e69f5aaa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c46bfa62e4b843b38c9abf10566660d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ddd9b64bef5471291ea8db8ae0bfe00":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"31be061d965443e0a0df01d0c46afdf4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"840c63f630ed45bea8ea14587a947cd1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"29efc36137844aa1aefcf9eff5f983a7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_56c4bb4ee51946faa079c126a5541cfd","IPY_MODEL_0611a6128cda42bcb6fb19e64a8bb8b2","IPY_MODEL_9a22ee840a6a4b33af1c5862c3dc9c7e"],"layout":"IPY_MODEL_1b890a0caef54e659a3ad55a02eac7f2"}},"56c4bb4ee51946faa079c126a5541cfd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_31abfa8522db4c52b16e4b68f5c83f6a","placeholder":"​","style":"IPY_MODEL_81a70ed088ad47938fd473c904cd00dc","value":"100%"}},"0611a6128cda42bcb6fb19e64a8bb8b2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_759beef2a79a43c4b2caea80a80c5075","max":15,"min":0,"orientation":"horizontal","style":"IPY_MODEL_21d3e3ac241d4ae6bdc755394b2d330f","value":15}},"9a22ee840a6a4b33af1c5862c3dc9c7e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_97e85e11592b44bb9dce82a297fb1662","placeholder":"​","style":"IPY_MODEL_225a020f261a4a10a5851491354535a8","value":" 15/15 [06:22&lt;00:00, 25.49s/it]"}},"1b890a0caef54e659a3ad55a02eac7f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"31abfa8522db4c52b16e4b68f5c83f6a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"81a70ed088ad47938fd473c904cd00dc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"759beef2a79a43c4b2caea80a80c5075":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"21d3e3ac241d4ae6bdc755394b2d330f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"97e85e11592b44bb9dce82a297fb1662":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"225a020f261a4a10a5851491354535a8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3372cbc55848450397786a4d23c34902":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_020f431ced0046a0b8612e48c362b99b","IPY_MODEL_bd5b606a15294392a361638084dddca4","IPY_MODEL_a2906b32daa3422eaf23a86002a0eeb3"],"layout":"IPY_MODEL_41a0047eca6045d2b117e8171fff30aa"}},"020f431ced0046a0b8612e48c362b99b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_19121d4e4e804729bde42011f89a8381","placeholder":"​","style":"IPY_MODEL_74ec4340ff7148e3a0c29939215c3ed7","value":"100%"}},"bd5b606a15294392a361638084dddca4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3d0b77884cde4d3093be535cd1873a94","max":15,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1552fd26b8864ab884e7b0a01473b12d","value":15}},"a2906b32daa3422eaf23a86002a0eeb3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_da6755aa49a242e2ada2637c75757001","placeholder":"​","style":"IPY_MODEL_0d865d4009fb44e9b5f1d224dd7272d8","value":" 15/15 [07:30&lt;00:00, 30.07s/it]"}},"41a0047eca6045d2b117e8171fff30aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"19121d4e4e804729bde42011f89a8381":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"74ec4340ff7148e3a0c29939215c3ed7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3d0b77884cde4d3093be535cd1873a94":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1552fd26b8864ab884e7b0a01473b12d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"da6755aa49a242e2ada2637c75757001":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d865d4009fb44e9b5f1d224dd7272d8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}