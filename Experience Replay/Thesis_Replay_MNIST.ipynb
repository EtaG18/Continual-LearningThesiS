{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMWceTB3WplJ0ynGo23rVp7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"b75877cd147d490aa9a80a80feffa10d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6954b5974ae24c3ca9b92326b5f65c39","IPY_MODEL_3451ad04c0704cb5b62df101fdb10042","IPY_MODEL_172d18f97be94f6a9c9a8d2645e04da2"],"layout":"IPY_MODEL_e6eef23c848d49d48a4606fd1e96908f"}},"6954b5974ae24c3ca9b92326b5f65c39":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b77f490604d546d4a2c8250bdfd32efa","placeholder":"​","style":"IPY_MODEL_afac02f1633b4e6390a7d0263fbb5456","value":"100%"}},"3451ad04c0704cb5b62df101fdb10042":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_22567a74de4e40dab9e04fe16a7d7f21","max":10,"min":0,"orientation":"horizontal","style":"IPY_MODEL_37b8956a23dc4978b138d38574e7efe4","value":10}},"172d18f97be94f6a9c9a8d2645e04da2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_53ff30862a7b44a5bad4ff91bdeb36df","placeholder":"​","style":"IPY_MODEL_e4fe1b9a76f3450f943796c0ed5e46de","value":" 10/10 [01:51&lt;00:00, 11.11s/it]"}},"e6eef23c848d49d48a4606fd1e96908f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b77f490604d546d4a2c8250bdfd32efa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"afac02f1633b4e6390a7d0263fbb5456":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"22567a74de4e40dab9e04fe16a7d7f21":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"37b8956a23dc4978b138d38574e7efe4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"53ff30862a7b44a5bad4ff91bdeb36df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e4fe1b9a76f3450f943796c0ed5e46de":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4e060417b9414d3d95e66fa7f6a1bfe7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_61cd84479ef3490db2a52cd3188530f1","IPY_MODEL_264d21753ed643c09bccb670b1b23b97","IPY_MODEL_e2c3ca73b8b84d59952cd89dde5dd374"],"layout":"IPY_MODEL_9d6292fc31f0476ab57150002c96153e"}},"61cd84479ef3490db2a52cd3188530f1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_46a5dfe86e87414881ae6190084c6884","placeholder":"​","style":"IPY_MODEL_21f2980f3e724dc898e43605b8bcafd9","value":"100%"}},"264d21753ed643c09bccb670b1b23b97":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fdc0f836dfde432a9f08943ba04c4025","max":10,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5e08ba91eaae4226b7a8890598b09c50","value":10}},"e2c3ca73b8b84d59952cd89dde5dd374":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a53fe9d3a95b4ad187799fa3a0e7e944","placeholder":"​","style":"IPY_MODEL_cd8bcb49173f4febb517543c061b829b","value":" 10/10 [03:38&lt;00:00, 21.93s/it]"}},"9d6292fc31f0476ab57150002c96153e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46a5dfe86e87414881ae6190084c6884":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"21f2980f3e724dc898e43605b8bcafd9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fdc0f836dfde432a9f08943ba04c4025":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e08ba91eaae4226b7a8890598b09c50":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a53fe9d3a95b4ad187799fa3a0e7e944":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd8bcb49173f4febb517543c061b829b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"4bSzwmz2KkHb"},"outputs":[],"source":["import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","source":["!git clone https://github.com/ContinualAI/colab.git continualai/colab"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rWx3R5eDMbRe","executionInfo":{"status":"ok","timestamp":1707385999139,"user_tz":-330,"elapsed":15,"user":{"displayName":"Achyuth Kasyap","userId":"12117926900346930702"}},"outputId":"6597e053-46af-496a-ba5c-2902442d79e2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'continualai/colab' already exists and is not an empty directory.\n"]}]},{"cell_type":"code","source":["from continualai.colab.scripts import mnist\n","mnist.init()\n","x_train, t_train, x_test, t_test = mnist.load()\n","\n","print(\"x_train dim and type: \", x_train.shape, x_train.dtype)\n","print(\"t_train dim and type: \", t_train.shape, t_train.dtype)\n","print(\"x_test dim and type: \", x_test.shape, x_test.dtype)\n","print(\"t_test dim and type: \", t_test.shape, t_test.dtype)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7W6cw5Z8L-UL","executionInfo":{"status":"ok","timestamp":1707385999139,"user_tz":-330,"elapsed":10,"user":{"displayName":"Achyuth Kasyap","userId":"12117926900346930702"}},"outputId":"329c4a4b-8b1d-49c7-ea17-7e46fa986417"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded!\n","x_train dim and type:  (60000, 1, 28, 28) float32\n","t_train dim and type:  (60000,) uint8\n","x_test dim and type:  (10000, 1, 28, 28) float32\n","t_test dim and type:  (10000,) uint8\n"]}]},{"cell_type":"code","source":["def split_mnist(train_x, train_y, test_x, test_y, n_splits=5):\n","    \"\"\" Given the training set, split the tensors by the class label. \"\"\"\n","    n_classes = 10\n","    if n_classes % n_splits != 0:\n","        print(\"n_classes should be a multiple of the number of splits!\")\n","        raise NotImplemented\n","    class_for_split = n_classes // n_splits\n","    mnist_train_test = [[],[]]  # train and test\n","    for id, data_set in enumerate([(train_x, train_y), (test_x, test_y)]):\n","        for i in range(n_splits):\n","            start = i * class_for_split\n","            end = (i + 1) * class_for_split\n","            split_idxs = np.where(np.logical_and(data_set[1] >= start, data_set[1] < end))[0]\n","            mnist_train_test[id].append((data_set[0][split_idxs], data_set[1][split_idxs]))\n","    return mnist_train_test"],"metadata":{"id":"emaktlriL-W4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","train_x, train_y, test_x, test_y = mnist.load()\n","splitmnist = split_mnist(train_x, train_y, test_x, test_y, n_splits=2)\n","# converting list to array\n","splitmnist = np.array(splitmnist)"],"metadata":{"id":"LWqlkohhL-ZY","executionInfo":{"status":"ok","timestamp":1707386000018,"user_tz":-330,"elapsed":886,"user":{"displayName":"Achyuth Kasyap","userId":"12117926900346930702"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"456d4c1f-7b2a-4854-c3fa-1df404d7f63a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-5-39dfc312fded>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  splitmnist = np.array(splitmnist)\n"]}]},{"cell_type":"code","source":["train_task1_data=splitmnist[0][0][0]\n","train_task1_label=splitmnist[0][0][1]\n","train_task2_data=splitmnist[0][1][0]\n","train_task2_label=splitmnist[0][1][1]\n","test_task1_data=splitmnist[1][0][0]\n","test_task1_label=splitmnist[1][0][1]\n","test_task2_data=splitmnist[1][1][0]\n","test_task2_label=splitmnist[1][1][1]"],"metadata":{"id":"7HcxoELpNKqZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train_task1 = torch.as_tensor(train_task1_data, dtype=torch.float32)\n","Y_train_task1 = torch.as_tensor(train_task1_label, dtype=torch.float32)\n","Y_train_task1=Y_train_task1.long()\n","X_test_task1 = torch.as_tensor(test_task1_data, dtype=torch.float32)\n","Y_test_task1 = torch.as_tensor(test_task1_label, dtype=torch.float32)\n","Y_test_task1=Y_test_task1.long()\n","\n","X_train_task2 = torch.as_tensor(train_task2_data, dtype=torch.float32)\n","Y_train_task2 = torch.as_tensor(train_task2_label, dtype=torch.float32)\n","Y_train_task2=Y_train_task2.long()\n","X_test_task2= torch.as_tensor(test_task2_data, dtype=torch.float32)\n","Y_test_task2 = torch.as_tensor(test_task2_label, dtype=torch.float32)\n","Y_test_task2=Y_test_task2.long()"],"metadata":{"id":"ePVGlGQ3f7-d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Y_train_task1=torch.nn.functional.one_hot(Y_train_task1, num_classes=10)\n","Y_test_task1=torch.nn.functional.one_hot(Y_test_task1, num_classes=10)\n","Y_train_task2=torch.nn.functional.one_hot(Y_train_task2, num_classes=10)\n","Y_test_task2=torch.nn.functional.one_hot(Y_test_task2, num_classes=10)"],"metadata":{"id":"nwJ_YmTQ7R8o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"x_train task-1 dim and type: \", X_train_task1.shape, X_train_task1.dtype)\n","print(\"t_train task-1 dim and type: \", Y_train_task1.shape, Y_train_task1.dtype)\n","print(\"x_test task-1 dim and type: \", X_test_task1.shape, X_test_task1.dtype)\n","print(\"t_test task-1 dim and type: \", Y_test_task1.shape, Y_test_task1.dtype)\n","\n","print(\"x_train task-2 dim and type: \", X_train_task2.shape, X_train_task2.dtype)\n","print(\"t_train task-2 dim and type: \", Y_train_task2.shape, Y_train_task2.dtype)\n","print(\"x_test task-2 dim and type: \", X_test_task2.shape, X_test_task2.dtype)\n","print(\"t_test task-2 dim and type: \", Y_test_task2.shape, Y_test_task2.dtype)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KStKGMJiivLi","executionInfo":{"status":"ok","timestamp":1707386000020,"user_tz":-330,"elapsed":11,"user":{"displayName":"Achyuth Kasyap","userId":"12117926900346930702"}},"outputId":"673a77c6-b4be-4635-fd78-0e164381e8d7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["x_train task-1 dim and type:  torch.Size([30596, 1, 28, 28]) torch.float32\n","t_train task-1 dim and type:  torch.Size([30596, 10]) torch.int64\n","x_test task-1 dim and type:  torch.Size([5139, 1, 28, 28]) torch.float32\n","t_test task-1 dim and type:  torch.Size([5139, 10]) torch.int64\n","x_train task-2 dim and type:  torch.Size([29404, 1, 28, 28]) torch.float32\n","t_train task-2 dim and type:  torch.Size([29404, 10]) torch.int64\n","x_test task-2 dim and type:  torch.Size([4861, 1, 28, 28]) torch.float32\n","t_test task-2 dim and type:  torch.Size([4861, 10]) torch.int64\n"]}]},{"cell_type":"code","source":["# task 1\n","task_1 = [(X_train_task1, Y_train_task1), (X_test_task1, Y_test_task1)]\n","\n","# task 2\n","task_2 = [(X_train_task2, Y_train_task2), (X_test_task2, Y_test_task2)]\n","\n","# task list\n","tasks = [task_1, task_2]"],"metadata":{"id":"HwI9eGg7f_Ye"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# switch to False to use CPU\n","use_cuda = True\n","use_cuda = use_cuda and torch.cuda.is_available()\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\");\n","torch.manual_seed(123123);\n","m = nn.LogSoftmax(dim=1)\n","Loss = nn.MSELoss()\n","batch_size=512"],"metadata":{"id":"xwsSKWjcgDot"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import precision_score, recall_score, f1_score\n","import torch.nn as nn\n","import torch.nn.functional as F\n","number_of_classes=10\n","\n","class ImprovedNet(nn.Module):\n","    def __init__(self):\n","        super(ImprovedNet, self).__init__()\n","\n","        # Convolutional layers\n","        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=0)\n","        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=0)\n","        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=0)\n","\n","        # Fully connected layers\n","        self.fc1 = nn.Linear(self.calculate_flattening_size(), 2048)\n","        self.fc2 = nn.Linear(2048, 256)\n","        self.fc3 = nn.Linear(256, number_of_classes)\n","\n","        # Activation\n","        self.act = nn.Softmax()\n","\n","    def calculate_flattening_size(self):\n","        # Dummy input to get the size after passing through convolutional layers\n","        x = torch.randn(512, 1, 28, 28)\n","        x = F.relu(self.conv1(x))\n","        x = F.relu(self.conv2(x))\n","        x = F.relu(self.conv3(x))\n","        return x.size(1) * x.size(2) * x.size(3)\n","\n","    def forward(self, x):\n","        x = F.relu(self.conv1(x))\n","        x = F.relu(self.conv2(x))\n","        x = F.relu(self.conv3(x))\n","\n","        # Dynamically compute the flattening size based on the shape of the output tensor\n","        x_size = x.size(1) * x.size(2) * x.size(3)\n","        x = x.view(-1, x_size)\n","\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = self.act(self.fc3(x))\n","        return x\n","\n","\n","def evaluate_metrics(model, device, x_data, t_data):\n","    model.eval()\n","    all_preds = []\n","    all_labels = []\n","\n","    for start in range(0, len(t_data)-1, batch_size):\n","        end = start + batch_size\n","        with torch.no_grad():\n","            x, y = torch.from_numpy(x_data[start:end]), torch.from_numpy(t_data[start:end])\n","            x, y = x.to(device), y.to(device)\n","            output = model(x)\n","            output = output.float()\n","            y = y.float()\n","\n","            # Convert predictions to numpy arrays\n","            preds = output.argmax(dim=1).cpu().numpy()\n","            labels = y.argmax(dim=1).cpu().numpy()\n","\n","            all_preds.extend(preds)\n","            all_labels.extend(labels)\n","\n","    # Calculate metrics\n","    precision = precision_score(all_labels, all_preds, average='weighted')\n","    recall = recall_score(all_labels, all_preds, average='weighted')\n","    f1 = f1_score(all_labels, all_preds, average='weighted')\n","\n","    return {'precision': precision, 'recall': recall, 'f1': f1}\n","\n","def train(model, device, x_train, t_train, optimizer, epoch):\n","    model.train()\n","\n","    for start in range(0, len(t_train)-1, batch_size):\n","      end = start + batch_size\n","      x, y = torch.from_numpy(x_train[start:end]), torch.from_numpy(t_train[start:end])\n","      y = y.type(torch.LongTensor)\n","      x, y = x.to(device), y.to(device)\n","      optimizer.zero_grad()\n","      output = model(x)\n","      y = y.squeeze()\n","      output = output.float()\n","      y = y.float()\n","      loss = Loss(output, y)\n","      loss.backward()\n","      optimizer.step()\n","      #print(loss.item())\n","    print('Train Epoch: {} \\tLoss: {:.6f}'.format(epoch, loss.item()))\n","\n","def test(model, device, x_test, t_test):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    all_preds = []\n","    all_labels = []\n","    batch_size = 1\n","\n","    for start in range(0, len(t_test)-1, batch_size):\n","        end = start + batch_size\n","        with torch.no_grad():\n","            x, y = torch.from_numpy(x_test[start:end]), torch.from_numpy(t_test[start:end])\n","            x, y = x.to(device), y.to(device)\n","            output = model(x)\n","            output = output.float()\n","            y = y.float()\n","            test_loss += Loss(output, y) # sum up batch loss\n","            pred = output.max(1)[1]  # get the index of the max logit\n","            correct += pred.eq(y.max(1)[1]).sum().item()\n","\n","            # Convert predictions to numpy arrays\n","            preds = pred.cpu().numpy()\n","            labels = y.argmax(dim=1).cpu().numpy()\n","\n","            all_preds.extend(preds)\n","            all_labels.extend(labels)\n","\n","    test_loss /= len(t_test)\n","\n","    # Calculate metrics\n","    precision = precision_score(all_labels, all_preds, average='weighted')\n","    recall = recall_score(all_labels, all_preds, average='weighted')\n","    f1 = f1_score(all_labels, all_preds, average='weighted')\n","\n","    print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n","        test_loss, correct, len(t_test), 100. * correct / len(t_test)))\n","    print('Precision: {:.4f}, Recall: {:.4f}, F1 Score: {:.4f}\\n'.format(precision, recall, f1))\n","\n","    return 100. * correct / len(t_test)"],"metadata":{"id":"lU02Kg5kgIOC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = ImprovedNet().to(device)\n","optimizer = optim.Adam(model.parameters(), lr=10**-5)"],"metadata":{"id":"EGYdT0OtgMWi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def shuffle_in_unison(dataset, seed, in_place=False):\n","    \"\"\" Shuffle two (or more) list in unison. \"\"\"\n","\n","    np.random.seed(seed)\n","    rng_state = np.random.get_state()\n","    new_dataset = []\n","    for x in dataset:\n","        if in_place:\n","            np.random.shuffle(x)\n","        else:\n","            new_dataset.append(np.random.permutation(x))\n","        np.random.set_state(rng_state)\n","\n","    if not in_place:\n","        return new_dataset"],"metadata":{"id":"6K5sul_Fgefc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.utils import shuffle\n","from sklearn.preprocessing import OneHotEncoder\n","\n","def balanced_replay_samples(data_features, data_labels, num_samples_per_task):\n","\n","  # Check if labels array has only two unique values\n","  unique_labels = np.unique(data_labels)\n","\n","  # print(unique_labels)\n","  if len(unique_labels) != 2:\n","    raise ValueError(\"This function expects data with only two unique labels.\")\n","\n","  # Create empty NumPy arrays for each class\n","  class1_features = np.empty((0,) + data_features.shape[1:])\n","  class2_features = np.empty((0,) + data_features.shape[1:])\n","  class1_labels = np.empty((0,) + data_labels.shape[1:])\n","  class2_labels = np.empty((0,) + data_labels.shape[1:])\n","\n","  # Zip features and labels for combined iteration\n","  combined_data = zip(data_features, data_labels)\n","\n","  # Iterate through zipped data, sorting into class arrays\n","  for features, label in combined_data:\n","    templabel = (np.argmax(label, axis=0)).reshape(-1, 1)\n","    if (templabel == unique_labels[0]):\n","      class1_features = np.concatenate((class1_features, [features]))\n","      class1_labels= np.concatenate((class1_labels, [label]))\n","    else:\n","      class2_features = np.concatenate((class2_features, [features]))\n","      class2_labels= np.concatenate((class2_labels, [label]))\n","\n","\n","  # Randomly select samples from each class array\n","  selected_class1_features = class1_features[:num_samples_per_task]\n","  selected_class1_labels = class1_labels[:num_samples_per_task]\n","  selected_class1_features, selected_class1_labels = shuffle(selected_class1_features, selected_class1_labels, random_state=45896)\n","\n","  selected_class2_features = class2_features[:num_samples_per_task]\n","  selected_class2_labels = class2_labels[:num_samples_per_task]\n","  selected_class2_features, selected_class2_labels = shuffle(selected_class2_features, selected_class2_labels, random_state=45896)\n","\n","  # Combine and return selected features and labels\n","  balanced_features = np.concatenate((selected_class1_features, selected_class2_features))\n","  balanced_labels = np.concatenate((selected_class1_labels,selected_class2_labels))\n","  balanced_features = torch.tensor(balanced_features, dtype=torch.float32)\n","  balanced_labels = torch.tensor(balanced_labels, dtype=torch.float32)\n","  balanced_features=np.asarray(balanced_features)\n","  balanced_labels=np.asarray(balanced_labels)\n","\n","  return balanced_features, balanced_labels"],"metadata":{"id":"ljq7plV7ubR0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import warnings\n","warnings.filterwarnings('ignore')\n","from tqdm.auto import tqdm\n","num_samples_per_task=3000\n","rehe_accs = []\n","for id, task in enumerate(tasks):\n","  avg_acc = 0\n","  print(\"Training on task: \", id)\n","\n","  (x_train, t_train), _ = task\n","\n","  # for previous task\n","  for i in range(id):\n","    (past_x_train, past_t_train), _ = tasks[i]\n","\n","    past_x_train, past_t_train = balanced_replay_samples(past_x_train, past_t_train, num_samples_per_task)\n","\n","    x_train = np.concatenate((x_train, past_x_train))\n","    t_train = np.concatenate((t_train, past_t_train))\n","\n","  x_train, t_train = shuffle_in_unison([x_train, t_train], 0)\n","\n","  for epoch in range(1, 100):\n","    train(model, device, x_train, t_train, optimizer, epoch)\n","\n","  for id_test, task in enumerate(tasks):\n","    print(\"Testing on task: \", id_test)\n","    _, (x_test, t_test) = task\n","    acc = test(model, device, x_test, t_test)\n","    avg_acc = avg_acc + acc\n","\n","  print(\"Avg acc: \", avg_acc / 2)\n","  rehe_accs.append(avg_acc/2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":819,"referenced_widgets":["b75877cd147d490aa9a80a80feffa10d","6954b5974ae24c3ca9b92326b5f65c39","3451ad04c0704cb5b62df101fdb10042","172d18f97be94f6a9c9a8d2645e04da2","e6eef23c848d49d48a4606fd1e96908f","b77f490604d546d4a2c8250bdfd32efa","afac02f1633b4e6390a7d0263fbb5456","22567a74de4e40dab9e04fe16a7d7f21","37b8956a23dc4978b138d38574e7efe4","53ff30862a7b44a5bad4ff91bdeb36df","e4fe1b9a76f3450f943796c0ed5e46de","4e060417b9414d3d95e66fa7f6a1bfe7","61cd84479ef3490db2a52cd3188530f1","264d21753ed643c09bccb670b1b23b97","e2c3ca73b8b84d59952cd89dde5dd374","9d6292fc31f0476ab57150002c96153e","46a5dfe86e87414881ae6190084c6884","21f2980f3e724dc898e43605b8bcafd9","fdc0f836dfde432a9f08943ba04c4025","5e08ba91eaae4226b7a8890598b09c50","a53fe9d3a95b4ad187799fa3a0e7e944","cd8bcb49173f4febb517543c061b829b"]},"id":"z51XLGtXgli-","executionInfo":{"status":"ok","timestamp":1707386385764,"user_tz":-330,"elapsed":381747,"user":{"displayName":"Achyuth Kasyap","userId":"12117926900346930702"}},"outputId":"128107e9-821c-443e-eb75-1e7a9d011fec"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training on task:  0\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/10 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b75877cd147d490aa9a80a80feffa10d"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Train Epoch: 1 \tLoss: 0.063442\n","Train Epoch: 2 \tLoss: 0.019830\n","Train Epoch: 3 \tLoss: 0.010554\n","Train Epoch: 4 \tLoss: 0.008178\n","Train Epoch: 5 \tLoss: 0.007222\n","Train Epoch: 6 \tLoss: 0.006577\n","Train Epoch: 7 \tLoss: 0.006072\n","Train Epoch: 8 \tLoss: 0.005658\n","Train Epoch: 9 \tLoss: 0.005305\n","Train Epoch: 10 \tLoss: 0.004992\n","Testing on task:  0\n","Test set: Average loss: 0.0035, Accuracy: 5029/5139 (98%)\n","Precision: 0.9787, Recall: 0.9788, F1 Score: 0.9787\n","\n","Testing on task:  1\n","Test set: Average loss: 0.1638, Accuracy: 0/4861 (0%)\n","Precision: 0.0000, Recall: 0.0000, F1 Score: 0.0000\n","\n","Avg acc:  48.92975287020821\n","Training on task:  1\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/10 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e060417b9414d3d95e66fa7f6a1bfe7"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Train Epoch: 1 \tLoss: 0.049499\n","Train Epoch: 2 \tLoss: 0.012920\n","Train Epoch: 3 \tLoss: 0.010286\n","Train Epoch: 4 \tLoss: 0.008378\n","Train Epoch: 5 \tLoss: 0.007109\n","Train Epoch: 6 \tLoss: 0.006109\n","Train Epoch: 7 \tLoss: 0.005201\n","Train Epoch: 8 \tLoss: 0.004408\n","Train Epoch: 9 \tLoss: 0.003791\n","Train Epoch: 10 \tLoss: 0.003312\n","Testing on task:  0\n","Test set: Average loss: 0.0045, Accuracy: 4981/5139 (97%)\n","Precision: 0.9926, Recall: 0.9694, F1 Score: 0.9808\n","\n","Testing on task:  1\n","Test set: Average loss: 0.0074, Accuracy: 4626/4861 (95%)\n","Precision: 0.9802, Recall: 0.9519, F1 Score: 0.9658\n","\n","Avg acc:  96.0455378334592\n"]}]}]}