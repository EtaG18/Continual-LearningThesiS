{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":1014,"status":"ok","timestamp":1699516117393,"user":{"displayName":"Achyuth Kasyap","userId":"12117926900346930702"},"user_tz":-330},"id":"IbG-yOGQCd74"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D\n","from tensorflow.keras.layers import MaxPooling2D\n","from tensorflow.keras.layers import Activation\n","from tensorflow.keras.layers import Flatten\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras import layers\n","from tensorflow.keras import backend as K\n","import numpy as np\n","from tqdm import tqdm\n","\n","\n","def evaluate(model, test_x, test_y):\n","    acc = tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy')\n","    for imgs, labels in zip(test_x, test_y):\n","        preds = model.predict_on_batch(np.array([imgs]))\n","        acc.update_state(labels, preds)\n","    return round(100*acc.result().numpy(), 2)\n","\n","\n","def permute_task(train, test):\n","    train_shape, test_shape = train.shape, test.shape\n","    train_flat, test_flat = train.reshape((-1, 3072)), test.reshape((-1, 3072))\n","    idx = np.arange(train_flat.shape[1])\n","    np.random.shuffle(idx)\n","    train_permuted, test_permuted = train_flat[:, idx], test_flat[:, idx]\n","    return (train_permuted.reshape(train_shape), test_permuted.reshape(test_shape))\n","\n","\n","class Train:\n","\n","    def __init__(self, optimizer, loss_fn, prior_weights=None, lambda_=0.1):\n","        self.optimizer = optimizer\n","        self.loss_fn = loss_fn\n","        self.prior_weights = prior_weights\n","        self.lambda_ = lambda_\n","\n","    def train(self, model, epochs, train_task, fisher_matrix=None, test_tasks=None):\n","        # empty list to collect per epoch test acc of each task\n","        if test_tasks:\n","            test_acc = [[] for _ in test_tasks]\n","        else:\n","            test_acc = None\n","        for epoch in tqdm(range(epochs)):\n","            for batch in train_task:\n","                X, y = batch\n","                with tf.GradientTape() as tape:\n","                    pred = model(X)\n","                    loss = self.loss_fn(y, pred)\n","                    # if to execute training with EWC\n","                    if fisher_matrix is not None:\n","                        loss += self.compute_penalty_loss(model, fisher_matrix)\n","                grads = tape.gradient(loss, model.trainable_variables)\n","                self.optimizer.apply_gradients(zip(grads, model.trainable_variables))\n","            # evaluate with the test set of task after each epoch\n","            if test_acc:\n","                for i in range(len(test_tasks)):\n","                    test_acc[i].append(evaluate(model, test_tasks[i][0], test_tasks[i][1]))\n","        print(test_acc)\n","        return test_acc\n","\n","    def compute_penalty_loss(self, model, fisher_matrix):\n","        penalty = 0.\n","        for u, v, w in zip(fisher_matrix, model.weights, self.prior_weights):\n","            penalty += tf.math.reduce_sum(u * tf.math.square(v - w))\n","        return 0.5 * self.lambda_ * penalty\n","\n","\n","class EWC:\n","\n","    def __init__(self, prior_model, data_samples, num_sample=30):\n","        self.prior_model = prior_model\n","        self.prior_weights = prior_model.weights\n","        self.num_sample = num_sample\n","        self.data_samples = data_samples\n","        self.fisher_matrix = self.compute_fisher()\n","\n","    def compute_fisher(self):\n","        weights = self.prior_weights\n","        fisher_accum = np.array([np.zeros(layer.numpy().shape) for layer in weights],\n","                           dtype=object\n","                          )\n","        for j in tqdm(range(self.num_sample)):\n","            idx = np.random.randint(self.data_samples.shape[0])\n","            with tf.GradientTape() as tape:\n","                logits = tf.nn.log_softmax(self.prior_model(np.array([self.data_samples[idx]])))\n","            grads = tape.gradient(logits, weights)\n","            for m in range(len(weights)):\n","                fisher_accum[m] += np.square(grads[m])\n","        fisher_accum /= self.num_sample\n","        return fisher_accum\n","\n","    def get_fisher(self):\n","        return self.fisher_matrix\n","\n","\n","from keras.models import Sequential\n","from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D\n","\n","class MLP3:\n","    def __init__(self, input_shape=(32,32,3), hidden_layers_neuron_list=[200, 200], num_classes=100):\n","        self.input_shape = input_shape\n","        self.num_classes = num_classes\n","        self.hidden_layers_neuron_list = hidden_layers_neuron_list\n","        self.model = self.create_cnn()\n","\n","    def create_cnn(self):\n","        model = Sequential()\n","\n","        # Convolutional layers\n","        model.add(Conv2D(32, (3, 3), activation='relu', input_shape=self.input_shape))\n","        model.add(MaxPooling2D((2, 2)))\n","        model.add(Conv2D(64, (3, 3), activation='relu'))\n","        model.add(MaxPooling2D((2, 2)))\n","\n","        # Flatten layer\n","        model.add(Flatten())\n","\n","        # Dense layers\n","        model.add(Dense(self.hidden_layers_neuron_list[0], activation='relu'))\n","        model.add(Dense(self.hidden_layers_neuron_list[1], activation='relu'))\n","        model.add(Dense(self.hidden_layers_neuron_list[1], activation='relu'))\n","        model.add(Dense(self.hidden_layers_neuron_list[1], activation='relu'))\n","        model.add(Dense(self.hidden_layers_neuron_list[1], activation='relu'))\n","\n","        # Output layer\n","        model.add(Dense(self.num_classes, activation='softmax'))\n","\n","        return model\n","\n","    def get_uncompiled_model(self):\n","      return self.model\n","\n","    def get_compiled_model(self, optimizer, loss_fn, metrics ):\n","      compiled_model = self.model\n","      compiled_model.compile(optimizer, loss_fn, metrics)\n","      return compiled_model"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1699517908005,"user":{"displayName":"Achyuth Kasyap","userId":"12117926900346930702"},"user_tz":-330},"id":"6L25GCPzClMP"},"outputs":[],"source":["from tensorflow.keras.layers import Dense\n","from tensorflow.keras.datasets import cifar100\n","from tensorflow.keras.models import Sequential\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import numpy as np\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1699517911635,"user":{"displayName":"Achyuth Kasyap","userId":"12117926900346930702"},"user_tz":-330},"id":"wpoSXWyMCm4g"},"outputs":[],"source":["epochs = 5\n","lambda_ = 0.001\n","lr = 0.001\n","num_sample = 30\n","opt = tf.keras.optimizers.Adam(learning_rate=lr)\n","loss_fn=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":8433,"status":"ok","timestamp":1699517920746,"user":{"displayName":"Achyuth Kasyap","userId":"12117926900346930702"},"user_tz":-330},"id":"htGaqnu7Cx2q"},"outputs":[],"source":["(x_train_A, y_train_A), (x_test_A, y_test_A) = cifar100.load_data()\n","x_train_A = x_train_A.astype('float32')\n","x_test_A = x_test_A.astype('float32')\n","x_train_A /= 255\n","x_test_A /= 255\n","\n","train_A = tf.data.Dataset.from_tensor_slices((x_train_A, y_train_A)).shuffle(1000).batch(32)\n","test_A = (x_test_A, y_test_A)\n","\n","x_train_B, x_test_B = permute_task(x_train_A, x_test_A)\n","y_train_B, y_test_B = y_train_A, y_test_A\n","\n","train_B = tf.data.Dataset.from_tensor_slices((x_train_B, y_train_B)).shuffle(1000).batch(4)\n","test_B = (x_test_B, y_test_B)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"2fQGcsZJDFp1"},"outputs":[{"name":"stderr","output_type":"stream","text":[" 20%|██        | 1/5 [04:46\u003c19:06, 286.57s/it]"]}],"source":["mlp = MLP3()\n","\n","trn_gd = Train(opt, loss_fn)\n","model = mlp.get_compiled_model(opt, loss_fn, ['accuracy'])\n","\n","acc_prior_A = trn_gd.train(model, epochs, train_A, test_tasks=[test_A])[0]\n","model.save('CIFAR10_A.h5')\n","print('[INFO] Task A Original (SGD): {}'.format(acc_prior_A[-1]))"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNF/zKYDRhxD+8vHoGChsPy","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
