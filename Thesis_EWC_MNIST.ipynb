{"cells":[{"cell_type":"markdown","metadata":{"id":"d1y9VuJFYhZW"},"source":["# Permute-MNIST [Simple Model] PyTorch\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9um9ln-sYSS9"},"outputs":[],"source":["import torch\n","torch.cuda.is_available()\n","import torch\n","import torch.nn as nn\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import numpy as np\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31874,"status":"ok","timestamp":1701079840987,"user":{"displayName":"Achyuth Kasyap","userId":"12117926900346930702"},"user_tz":-330},"id":"vbTkhhwNYcUg","outputId":"c3c4d8be-b1f3-43d2-8c8e-71bf22ac05fc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'continualai/colab'...\n","remote: Enumerating objects: 378, done.\u001b[K\n","remote: Counting objects: 100% (120/120), done.\u001b[K\n","remote: Compressing objects: 100% (58/58), done.\u001b[K\n","remote: Total 378 (delta 78), reused 64 (delta 62), pack-reused 258\u001b[K\n","Receiving objects: 100% (378/378), 26.97 MiB | 7.26 MiB/s, done.\n","Resolving deltas: 100% (198/198), done.\n","Downloading train-images-idx3-ubyte.gz...\n","Downloading t10k-images-idx3-ubyte.gz...\n","Downloading train-labels-idx1-ubyte.gz...\n","Downloading t10k-labels-idx1-ubyte.gz...\n","Download complete.\n","Save complete.\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data/mnist/MNIST/raw/train-images-idx3-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 9912422/9912422 [00:01<00:00, 5016005.25it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting data/mnist/MNIST/raw/train-images-idx3-ubyte.gz to data/mnist/MNIST/raw\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 28881/28881 [00:00<00:00, 131985.28it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz to data/mnist/MNIST/raw\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1648877/1648877 [00:01<00:00, 1203774.89it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to data/mnist/MNIST/raw\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 4542/4542 [00:00<00:00, 4222191.66it/s]"]},{"name":"stdout","output_type":"stream","text":["Extracting data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/mnist/MNIST/raw\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["!git clone https://github.com/ContinualAI/colab.git continualai/colab\n","from continualai.colab.scripts import mnist\n","mnist.init()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1701079854478,"user":{"displayName":"Achyuth Kasyap","userId":"12117926900346930702"},"user_tz":-330},"id":"PykKsyd-Yl7i","outputId":"609e5b5d-549a-4f39-fa5b-a473ac9118a1"},"outputs":[{"name":"stdout","output_type":"stream","text":["x_train dim and type:  (60000, 1, 28, 28) float32\n","t_train dim and type:  (60000,) uint8\n","x_test dim and type:  (10000, 1, 28, 28) float32\n","t_test dim and type:  (10000,) uint8\n"]}],"source":["x_train, t_train, x_test, t_test = mnist.load()\n","\n","print(\"x_train dim and type: \", x_train.shape, x_train.dtype)\n","print(\"t_train dim and type: \", t_train.shape, t_train.dtype)\n","print(\"x_test dim and type: \", x_test.shape, x_test.dtype)\n","print(\"t_test dim and type: \", t_test.shape, t_test.dtype)\n","batch_size=128"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3YrZaXTZYqf3"},"outputs":[],"source":["# switch to False to use CPU\n","use_cuda = True\n","\n","use_cuda = use_cuda and torch.cuda.is_available()\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\");\n","torch.manual_seed(1);"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UNzF_uKkYq--"},"outputs":[],"source":["import torch.nn.functional as F\n","\n","class SimpleNet(nn.Module):\n","    def __init__(self):\n","        super(SimpleNet, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n","        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n","        self.conv2_drop = nn.Dropout2d()\n","        self.fc1 = nn.Linear(320, 50)\n","        self.fc2 = nn.Linear(50, 10)\n","\n","    def forward(self, x):\n","        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n","        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n","        x = x.view(-1, 320)\n","        x = F.relu(self.fc1(x))\n","        x = F.dropout(x, training=self.training)\n","        x = self.fc2(x)\n","        # print(x.shape)\n","        return x\n","\n","def permute_mnist(mnist, seed):\n","    \"\"\" Given the training set, permute pixels of each img the same way. \"\"\"\n","\n","    np.random.seed(seed)\n","    print(\"starting permutation...\")\n","    h = w = 28\n","    perm_inds = list(range(h*w))\n","    np.random.shuffle(perm_inds)\n","    # print(perm_inds)\n","    perm_mnist = []\n","    for set in mnist:\n","        num_img = set.shape[0]\n","        flat_set = set.reshape(num_img, w * h)\n","        perm_mnist.append(flat_set[:, perm_inds].reshape(num_img, 1, w, h))\n","    print(\"done.\")\n","    return perm_mnist\n","\n","def on_task_update(task_id, x_mem, t_mem):\n","\n","  model.train()\n","  fisher_dict[task_id] = {}\n","  optpar_dict[task_id] = {}\n","  count=0\n","  for name, param in model.named_parameters():\n","    fisher_dict[task_id][name] = param.data*0.0\n","  for start in range(0, len(t_mem)-1, batch_size):\n","      optimizer.zero_grad()\n","      count+=1\n","      # print(len(t_mem),len(x_mem))\n","      end = start + batch_size\n","      x, y = torch.from_numpy(x_mem[start:end]), torch.from_numpy(t_mem[start:end]).long()\n","      x, y = x.to(device), y.to(device)\n","      output = model(x)\n","      loss = F.cross_entropy(output, y)\n","      loss.backward()\n","      # gradients accumulated can be used to calculate fisher\n","      for name, param in model.named_parameters():\n","        fisher_dict[task_id][name] += param.grad.data.clone().pow(2)\n","  for name, param in model.named_parameters():\n","        optpar_dict[task_id][name] = param.data.clone()\n","        fisher_dict[task_id][name] = fisher_dict[task_id][name]/count\n","\n","def train_ewc(model, device, task_id, x_train, t_train, optimizer, epoch):\n","    model.train()\n","\n","    for start in range(0, len(t_train)-1, batch_size):\n","      end = start + batch_size\n","      x, y = torch.from_numpy(x_train[start:end]), torch.from_numpy(t_train[start:end]).long()\n","      x, y = x.to(device), y.to(device)\n","\n","      optimizer.zero_grad()\n","\n","      output = model(x)\n","      loss = F.cross_entropy(output, y)\n","\n","      ### magic here! :-)\n","      for task in range(task_id):\n","        for name, param in model.named_parameters():\n","          fisher = fisher_dict[task][name]\n","          optpar = optpar_dict[task][name]\n","          loss += (fisher * (optpar - param).pow(2)).sum() * ewc_lambda\n","\n","      loss.backward()\n","      optimizer.step()\n","      #print(loss.item())\n","    print('Train Epoch: {} \\tLoss: {:.6f}'.format(epoch, loss.item()))\n","\n","def train(model, device, x_train, t_train, optimizer, epoch):\n","    model.train()\n","\n","    for start in range(0, len(t_train)-1, batch_size):\n","      end = start + batch_size\n","      x, y = torch.from_numpy(x_train[start:end]), torch.from_numpy(t_train[start:end]).long()\n","      x, y = x.to(device), y.to(device)\n","\n","      optimizer.zero_grad()\n","\n","      output = model(x)\n","      loss = F.cross_entropy(output, y)\n","      loss.backward()\n","      optimizer.step()\n","      #print(loss.item())\n","    print('Train Epoch: {} \\tLoss: {:.6f}'.format(epoch, loss.item()))\n","\n","def test(model, device, x_test, t_test):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    for start in range(0, len(t_test)-1, batch_size):\n","      end = start + batch_size\n","      with torch.no_grad():\n","        x, y = torch.from_numpy(x_test[start:end]), torch.from_numpy(t_test[start:end]).long()\n","        x, y = x.to(device), y.to(device)\n","        output = model(x)\n","        test_loss += F.cross_entropy(output, y).item() # sum up batch loss\n","        pred = output.max(1, keepdim=True)[1] # get the index of the max logit\n","        correct += pred.eq(y.view_as(pred)).sum().item()\n","\n","    test_loss /= len(t_test)\n","    print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n","        test_loss, correct, len(t_test),\n","        100. * correct / len(t_test)))\n","    return 100. * correct / len(t_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iFUV7TvsNLoq"},"outputs":[],"source":["# ACCURACY PRECISION RECALL F1-SCORE\n","\n","from sklearn.metrics import precision_score, recall_score, f1_score\n","class SimpleNet(nn.Module):\n","    def __init__(self):\n","        super(SimpleNet, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n","        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n","        self.conv2_drop = nn.Dropout2d()\n","        self.fc1 = nn.Linear(320, 50)\n","        self.fc2 = nn.Linear(50, 10)\n","\n","    def forward(self, x):\n","        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n","        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n","        x = x.view(-1, 320)\n","        x = F.relu(self.fc1(x))\n","        x = F.dropout(x, training=self.training)\n","        x = self.fc2(x)\n","        # print(x.shape)\n","        return x\n","\n","def permute_mnist(mnist, seed):\n","    \"\"\" Given the training set, permute pixels of each img the same way. \"\"\"\n","\n","    np.random.seed(seed)\n","    print(\"starting permutation...\")\n","    h = w = 28\n","    perm_inds = list(range(h*w))\n","    np.random.shuffle(perm_inds)\n","    # print(perm_inds)\n","    perm_mnist = []\n","    for set in mnist:\n","        num_img = set.shape[0]\n","        flat_set = set.reshape(num_img, w * h)\n","        perm_mnist.append(flat_set[:, perm_inds].reshape(num_img, 1, w, h))\n","    print(\"done.\")\n","    return perm_mnist\n","\n","\n","def on_task_update(task_id, x_mem, t_mem):\n","\n","  model.train()\n","  fisher_dict[task_id] = {}\n","  optpar_dict[task_id] = {}\n","  count=0\n","  for name, param in model.named_parameters():\n","    fisher_dict[task_id][name] = param.data*0.0\n","  for start in range(0, len(t_mem)-1, batch_size):\n","      optimizer.zero_grad()\n","      count+=1\n","      # print(len(t_mem),len(x_mem))\n","      end = start + batch_size\n","      x, y = torch.from_numpy(x_mem[start:end]), torch.from_numpy(t_mem[start:end]).long()\n","      x, y = x.to(device), y.to(device)\n","      output = model(x)\n","      loss = F.cross_entropy(output, y)\n","      loss.backward()\n","      # gradients accumulated can be used to calculate fisher\n","      for name, param in model.named_parameters():\n","        fisher_dict[task_id][name] += param.grad.data.clone().pow(2)\n","  for name, param in model.named_parameters():\n","        optpar_dict[task_id][name] = param.data.clone()\n","        fisher_dict[task_id][name] = fisher_dict[task_id][name]/count\n","\n","def train_ewc(model, device, task_id, x_train, t_train, optimizer, epoch):\n","    model.train()\n","\n","    for start in range(0, len(t_train)-1, batch_size):\n","        end = start + batch_size\n","        x, y = torch.from_numpy(x_train[start:end]), torch.from_numpy(t_train[start:end]).long()\n","        x, y = x.to(device), y.to(device)\n","\n","        optimizer.zero_grad()\n","\n","        output = model(x)\n","        loss = F.cross_entropy(output, y)\n","\n","        ### magic here! :-)\n","        for task in range(task_id):\n","            for name, param in model.named_parameters():\n","                fisher = fisher_dict[task][name]\n","                optpar = optpar_dict[task][name]\n","                loss += (fisher * (optpar - param).pow(2)).sum() * ewc_lambda\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","    # After each epoch, evaluate and print metrics\n","    train_metrics = evaluate_metrics(model, device, x_train, t_train)\n","    # print(f'Train Epoch: {epoch}\\tLoss: {loss.item():.6f}\\tPrecision: {train_metrics[\"precision\"]:.4f}\\tRecall: {train_metrics[\"recall\"]:.4f}\\tF1 Score: {train_metrics[\"f1\"]:.4f}')\n","\n","def evaluate_metrics(model, device, x_data, t_data):\n","    model.eval()\n","    all_preds = []\n","    all_labels = []\n","\n","    for start in range(0, len(t_data)-1, batch_size):\n","        end = start + batch_size\n","        with torch.no_grad():\n","            x, y = torch.from_numpy(x_data[start:end]), torch.from_numpy(t_data[start:end]).long()\n","            x, y = x.to(device), y.to(device)\n","            output = model(x)\n","\n","            # Convert predictions to numpy arrays\n","            preds = output.argmax(dim=1).cpu().numpy()\n","            labels = y.cpu().numpy()\n","\n","            all_preds.extend(preds)\n","            all_labels.extend(labels)\n","\n","    # Calculate metrics\n","    precision = precision_score(all_labels, all_preds, average='weighted')\n","    recall = recall_score(all_labels, all_preds, average='weighted')\n","    f1 = f1_score(all_labels, all_preds, average='weighted')\n","\n","    return {'precision': precision, 'recall': recall, 'f1': f1}\n","\n","def train(model, device, x_train, t_train, optimizer, epoch):\n","    model.train()\n","\n","    for start in range(0, len(t_train)-1, batch_size):\n","      end = start + batch_size\n","      x, y = torch.from_numpy(x_train[start:end]), torch.from_numpy(t_train[start:end]).long()\n","      x, y = x.to(device), y.to(device)\n","\n","      optimizer.zero_grad()\n","\n","      output = model(x)\n","      loss = F.cross_entropy(output, y)\n","      loss.backward()\n","      optimizer.step()\n","      #print(loss.item())\n","    # print('Train Epoch: {} \\tLoss: {:.6f}'.format(epoch, loss.item()))\n","\n","def test(model, device, x_test, t_test):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    all_preds = []\n","    all_labels = []\n","\n","    for start in range(0, len(t_test)-1, batch_size):\n","        end = start + batch_size\n","        with torch.no_grad():\n","            x, y = torch.from_numpy(x_test[start:end]), torch.from_numpy(t_test[start:end]).long()\n","            x, y = x.to(device), y.to(device)\n","            output = model(x)\n","            test_loss += F.cross_entropy(output, y).item()  # sum up batch loss\n","            pred = output.max(1, keepdim=True)[1]  # get the index of the max logit\n","            correct += pred.eq(y.view_as(pred)).sum().item()\n","\n","            # Convert predictions to numpy arrays\n","            preds = pred.cpu().numpy()\n","            labels = y.cpu().numpy()\n","\n","            all_preds.extend(preds)\n","            all_labels.extend(labels)\n","\n","    test_loss /= len(t_test)\n","\n","    # Calculate metrics\n","    precision = precision_score(all_labels, all_preds, average='weighted')\n","    recall = recall_score(all_labels, all_preds, average='weighted')\n","    f1 = f1_score(all_labels, all_preds, average='weighted')\n","\n","    print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n","        test_loss, correct, len(t_test), 100. * correct / len(t_test)))\n","    print('Precision: {:.4f}, Recall: {:.4f}, F1 Score: {:.4f}\\n'.format(precision, recall, f1))\n","\n","    return 100. * correct / len(t_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2001,"status":"ok","timestamp":1701079864587,"user":{"displayName":"Achyuth Kasyap","userId":"12117926900346930702"},"user_tz":-330},"id":"wroiCam8YuEf","outputId":"6b68b75d-3cef-43db-e2f5-adfecd6030a9"},"outputs":[{"name":"stdout","output_type":"stream","text":["starting permutation...\n","done.\n","starting permutation...\n","done.\n"]}],"source":["# task 1\n","task_1 = [(x_train, t_train), (x_test, t_test)]\n","\n","# task 2\n","x_train2, x_test2 = permute_mnist([x_train, x_test], 1)\n","task_2 = [(x_train2, t_train), (x_test2, t_test)]\n","\n","# task 3\n","x_train3, x_test3 = permute_mnist([x_train, x_test], 2)\n","task_3 = [(x_train3, t_train), (x_test3, t_test)]\n","\n","# task list\n","tasks = [task_1, task_2, task_3]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TMk-YLtwY8td"},"outputs":[],"source":["model = SimpleNet().to(device)\n","optimizer = optim.Adam(model.parameters(), lr=0.0001)\n","fisher_dict = {}\n","optpar_dict = {}\n","ewc_lambda = 5000"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":94201,"status":"ok","timestamp":1701079972141,"user":{"displayName":"Achyuth Kasyap","userId":"12117926900346930702"},"user_tz":-330},"id":"X5t8jRVZZH_Q","outputId":"784b94d2-d1ea-4944-c9cf-c1df8b66920a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training on task:  0\n","Testing on task:  0\n","Test set: Average loss: 0.0012, Accuracy: 9531/10000 (95%)\n","Precision: 0.9532, Recall: 0.9531, F1 Score: 0.9530\n","\n","Testing on task:  1\n","Test set: Average loss: 0.0226, Accuracy: 691/10000 (7%)\n","Precision: 0.0356, Recall: 0.0691, F1 Score: 0.0428\n","\n","Testing on task:  2\n","Test set: Average loss: 0.0198, Accuracy: 1200/10000 (12%)\n","Precision: 0.0964, Recall: 0.1200, F1 Score: 0.0782\n","\n","Avg acc:  38.07333333333333\n","Training on task:  1\n","Testing on task:  0\n","Test set: Average loss: 0.0018, Accuracy: 9430/10000 (94%)\n","Precision: 0.9443, Recall: 0.9430, F1 Score: 0.9431\n","\n","Testing on task:  1\n","Test set: Average loss: 0.0172, Accuracy: 2292/10000 (23%)\n","Precision: 0.2094, Recall: 0.2292, F1 Score: 0.1913\n","\n","Testing on task:  2\n","Test set: Average loss: 0.0181, Accuracy: 1454/10000 (15%)\n","Precision: 0.1185, Recall: 0.1454, F1 Score: 0.1037\n","\n","Avg acc:  43.919999999999995\n","Training on task:  2\n","Testing on task:  0\n","Test set: Average loss: 0.0015, Accuracy: 9480/10000 (95%)\n","Precision: 0.9486, Recall: 0.9480, F1 Score: 0.9480\n","\n","Testing on task:  1\n","Test set: Average loss: 0.0183, Accuracy: 1033/10000 (10%)\n","Precision: 0.1270, Recall: 0.1033, F1 Score: 0.0877\n","\n","Testing on task:  2\n","Test set: Average loss: 0.0168, Accuracy: 2502/10000 (25%)\n","Precision: 0.2389, Recall: 0.2502, F1 Score: 0.2339\n","\n","Avg acc:  43.38333333333333\n"]}],"source":["import warnings\n","warnings.filterwarnings('ignore')\n","ewc_accs = []\n","for id, task in enumerate(tasks):\n","  avg_acc = 0\n","  print(\"Training on task: \", id)\n","\n","  (x_train, t_train), _ = task\n","\n","  for epoch in range(1, 11):\n","    train_ewc(model, device, id, x_train, t_train, optimizer, epoch)\n","  on_task_update(id, x_train, t_train)\n","\n","  for id_test, task in enumerate(tasks):\n","    print(\"Testing on task: \", id_test)\n","    _, (x_test, t_test) = task\n","    acc = test(model, device, x_test, t_test)\n","    avg_acc = avg_acc + acc\n","\n","  print(\"Avg acc: \", avg_acc / 3)\n","  ewc_accs.append(avg_acc / 3)"]},{"cell_type":"markdown","metadata":{"id":"AOkNHD0feU5G"},"source":["# Permuted-MNIST ONE ARCHITECTURE\n"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"00ISaOBoeZbt","executionInfo":{"status":"ok","timestamp":1701760866658,"user_tz":-330,"elapsed":13,"user":{"displayName":"Achyuth Kasyap","userId":"12117926900346930702"}}},"outputs":[],"source":["import torch\n","# torch.cuda.is_available()\n","import torch\n","import torch.nn\n","import torch.nn as nn\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from tqdm.auto import tqdm"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24233,"status":"ok","timestamp":1701760586979,"user":{"displayName":"Achyuth Kasyap","userId":"12117926900346930702"},"user_tz":-330},"id":"vYcducP6fAwo","outputId":"51c1347a-d0fa-4774-8476-efb7005e90e7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'continualai/colab'...\n","remote: Enumerating objects: 378, done.\u001b[K\n","remote: Counting objects: 100% (120/120), done.\u001b[K\n","remote: Compressing objects: 100% (58/58), done.\u001b[K\n","remote: Total 378 (delta 78), reused 64 (delta 62), pack-reused 258\u001b[K\n","Receiving objects: 100% (378/378), 26.97 MiB | 11.41 MiB/s, done.\n","Resolving deltas: 100% (198/198), done.\n","Downloading train-images-idx3-ubyte.gz...\n","Downloading t10k-images-idx3-ubyte.gz...\n","Downloading train-labels-idx1-ubyte.gz...\n","Downloading t10k-labels-idx1-ubyte.gz...\n","Download complete.\n","Save complete.\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data/mnist/MNIST/raw/train-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9912422/9912422 [00:02<00:00, 4411339.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting data/mnist/MNIST/raw/train-images-idx3-ubyte.gz to data/mnist/MNIST/raw\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28881/28881 [00:00<00:00, 134616.31it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz to data/mnist/MNIST/raw\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1648877/1648877 [00:01<00:00, 1275467.83it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to data/mnist/MNIST/raw\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4542/4542 [00:00<00:00, 9855420.99it/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/mnist/MNIST/raw\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["!git clone https://github.com/ContinualAI/colab.git continualai/colab\n","from continualai.colab.scripts import mnist\n","mnist.init()"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":643,"status":"ok","timestamp":1701760594902,"user":{"displayName":"Achyuth Kasyap","userId":"12117926900346930702"},"user_tz":-330},"id":"nbHmBW0ofDRA","outputId":"5e0744d7-2b79-43a5-ecaa-dc01cde8661c"},"outputs":[{"output_type":"stream","name":"stdout","text":["x_train dim and type:  (60000, 1, 28, 28) float32\n","t_train dim and type:  (60000,) uint8\n","x_test dim and type:  (10000, 1, 28, 28) float32\n","t_test dim and type:  (10000,) uint8\n"]}],"source":["x_train, t_train, x_test, t_test = mnist.load()\n","\n","print(\"x_train dim and type: \", x_train.shape, x_train.dtype)\n","print(\"t_train dim and type: \", t_train.shape, t_train.dtype)\n","print(\"x_test dim and type: \", x_test.shape, x_test.dtype)\n","print(\"t_test dim and type: \", t_test.shape, t_test.dtype)"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"yzaCp3DOfF_T","executionInfo":{"status":"ok","timestamp":1701760614206,"user_tz":-330,"elapsed":1046,"user":{"displayName":"Achyuth Kasyap","userId":"12117926900346930702"}}},"outputs":[],"source":["# switch to False to use CPU\n","use_cuda = True\n","\n","use_cuda = use_cuda and torch.cuda.is_available()\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\");\n","torch.manual_seed(1);"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"3sGtDlCqfIlF","executionInfo":{"status":"ok","timestamp":1701760682090,"user_tz":-330,"elapsed":1019,"user":{"displayName":"Achyuth Kasyap","userId":"12117926900346930702"}}},"outputs":[],"source":["import torch.nn.functional as F\n","\n","class ONEArchitecture(nn.Module):\n","    def __init__(self):\n","        super(ONEArchitecture, self).__init__()\n","\n","        # Convolutional layers\n","        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n","        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n","        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n","\n","        # Fully connected layers\n","        self.fc1 = nn.Linear(100352, 512)\n","        self.fc2 = nn.Linear(512, 256)\n","        self.fc3 = nn.Linear(256, 10)\n","\n","    def forward(self, x):\n","        x = F.relu(self.conv1(x))\n","\n","        x = F.relu(self.conv2(x))\n","\n","        x = F.relu(self.conv3(x))\n","\n","        # Flatten the tensor before passing it to fully connected layers\n","        x = x.view(-1, 100352)\n","\n","        x = F.relu(self.fc1(x))\n","\n","        x = F.relu(self.fc2(x))\n","\n","        x = self.fc3(x)\n","        return x\n","\n","def permute_mnist(mnist, seed):\n","    \"\"\" Given the training set, permute pixels of each img the same way. \"\"\"\n","\n","    np.random.seed(seed)\n","    print(\"starting permutation...\")\n","    h = w = 28\n","    perm_inds = list(range(h*w))\n","    np.random.shuffle(perm_inds)\n","    # print(perm_inds)\n","    perm_mnist = []\n","    for set in mnist:\n","        print(set.shape)\n","        num_img = set.shape[0]\n","        flat_set = set.reshape(num_img, w * h)\n","        perm_mnist.append(flat_set[:, perm_inds].reshape(num_img, 1, w, h))\n","    print(\"done.\")\n","    return perm_mnist\n","\n","from sklearn.metrics import precision_score, recall_score, f1_score\n","\n","def on_task_update(task_id, x_mem, t_mem):\n","\n","  model.train()\n","  fisher_dict[task_id] = {}\n","  optpar_dict[task_id] = {}\n","  count=0\n","  for name, param in model.named_parameters():\n","    fisher_dict[task_id][name] = param.data*0.0\n","  for start in range(0, len(t_mem)-1, batch_size):\n","      optimizer.zero_grad()\n","      count+=1\n","      # print(len(t_mem),len(x_mem))\n","      end = start + batch_size\n","      x, y = torch.from_numpy(x_mem[start:end]), torch.from_numpy(t_mem[start:end]).long()\n","      x, y = x.to(device), y.to(device)\n","      output = model(x)\n","      loss = F.cross_entropy(output, y)\n","      loss.backward()\n","      # gradients accumulated can be used to calculate fisher\n","      for name, param in model.named_parameters():\n","        fisher_dict[task_id][name] += param.grad.data.clone().pow(2)\n","  for name, param in model.named_parameters():\n","        optpar_dict[task_id][name] = param.data.clone()\n","        fisher_dict[task_id][name] = fisher_dict[task_id][name]/count\n","\n","def train_ewc(model, device, task_id, x_train, t_train, optimizer, epoch):\n","    model.train()\n","\n","    for start in range(0, len(t_train)-1, batch_size):\n","        end = start + batch_size\n","        x, y = torch.from_numpy(x_train[start:end]), torch.from_numpy(t_train[start:end]).long()\n","        x, y = x.to(device), y.to(device)\n","\n","        optimizer.zero_grad()\n","\n","        output = model(x)\n","        loss = F.cross_entropy(output, y)\n","\n","        ### magic here! :-)\n","        for task in range(task_id):\n","            for name, param in model.named_parameters():\n","                fisher = fisher_dict[task][name]\n","                optpar = optpar_dict[task][name]\n","                loss += (fisher * (optpar - param).pow(2)).sum() * ewc_lambda\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","    # After each epoch, evaluate and print metrics\n","    train_metrics = evaluate_metrics(model, device, x_train, t_train)\n","    # print(f'Train Epoch: {epoch}\\tLoss: {loss.item():.6f}\\tPrecision: {train_metrics[\"precision\"]:.4f}\\tRecall: {train_metrics[\"recall\"]:.4f}\\tF1 Score: {train_metrics[\"f1\"]:.4f}')\n","\n","def evaluate_metrics(model, device, x_data, t_data):\n","    model.eval()\n","    all_preds = []\n","    all_labels = []\n","\n","    for start in range(0, len(t_data)-1, batch_size):\n","        end = start + batch_size\n","        with torch.no_grad():\n","            x, y = torch.from_numpy(x_data[start:end]), torch.from_numpy(t_data[start:end]).long()\n","            x, y = x.to(device), y.to(device)\n","            output = model(x)\n","\n","            # Convert predictions to numpy arrays\n","            preds = output.argmax(dim=1).cpu().numpy()\n","            labels = y.cpu().numpy()\n","\n","            all_preds.extend(preds)\n","            all_labels.extend(labels)\n","\n","    # Calculate metrics\n","    precision = precision_score(all_labels, all_preds, average='weighted')\n","    recall = recall_score(all_labels, all_preds, average='weighted')\n","    f1 = f1_score(all_labels, all_preds, average='weighted')\n","\n","    return {'precision': precision, 'recall': recall, 'f1': f1}\n","\n","def train(model, device, x_train, t_train, optimizer, epoch):\n","    model.train()\n","\n","    for start in range(0, len(t_train)-1, batch_size):\n","      end = start + batch_size\n","      x, y = torch.from_numpy(x_train[start:end]), torch.from_numpy(t_train[start:end]).long()\n","      x, y = x.to(device), y.to(device)\n","\n","      optimizer.zero_grad()\n","\n","      output = model(x)\n","      loss = F.cross_entropy(output, y)\n","      loss.backward()\n","      optimizer.step()\n","      #print(loss.item())\n","    # print('Train Epoch: {} \\tLoss: {:.6f}'.format(epoch, loss.item()))\n","\n","def test(model, device, x_test, t_test):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    all_preds = []\n","    all_labels = []\n","\n","    for start in range(0, len(t_test)-1, batch_size):\n","        end = start + batch_size\n","        with torch.no_grad():\n","            x, y = torch.from_numpy(x_test[start:end]), torch.from_numpy(t_test[start:end]).long()\n","            x, y = x.to(device), y.to(device)\n","            output = model(x)\n","            test_loss += F.cross_entropy(output, y).item()  # sum up batch loss\n","            pred = output.max(1, keepdim=True)[1]  # get the index of the max logit\n","            correct += pred.eq(y.view_as(pred)).sum().item()\n","\n","            # Convert predictions to numpy arrays\n","            preds = pred.cpu().numpy()\n","            labels = y.cpu().numpy()\n","\n","            all_preds.extend(preds)\n","            all_labels.extend(labels)\n","\n","    test_loss /= len(t_test)\n","\n","    # Calculate metrics\n","    precision = precision_score(all_labels, all_preds, average='weighted')\n","    recall = recall_score(all_labels, all_preds, average='weighted')\n","    f1 = f1_score(all_labels, all_preds, average='weighted')\n","\n","    print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n","        test_loss, correct, len(t_test), 100. * correct / len(t_test)))\n","    print('Precision: {:.4f}, Recall: {:.4f}, F1 Score: {:.4f}\\n'.format(precision, recall, f1))\n","\n","    return 100. * correct / len(t_test)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2161,"status":"ok","timestamp":1701760687707,"user":{"displayName":"Achyuth Kasyap","userId":"12117926900346930702"},"user_tz":-330},"id":"4PNwfgCcfLbn","outputId":"88002362-fafa-459c-b1b4-fad862f980c3"},"outputs":[{"output_type":"stream","name":"stdout","text":["starting permutation...\n","(60000, 1, 28, 28)\n","(10000, 1, 28, 28)\n","done.\n","starting permutation...\n","(60000, 1, 28, 28)\n","(10000, 1, 28, 28)\n","done.\n"]}],"source":["# task 1\n","task_1 = [(x_train, t_train), (x_test, t_test)]\n","\n","# task 2\n","x_train2, x_test2 = permute_mnist([x_train, x_test], 1)\n","task_2 = [(x_train2, t_train), (x_test2, t_test)]\n","\n","# task 3\n","x_train3, x_test3 = permute_mnist([x_train, x_test], 2)\n","task_3 = [(x_train3, t_train), (x_test3, t_test)]\n","\n","# task list\n","tasks = [task_1, task_2, task_3]"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"ef5nhdu-fNt5","executionInfo":{"status":"ok","timestamp":1701760701248,"user_tz":-330,"elapsed":7027,"user":{"displayName":"Achyuth Kasyap","userId":"12117926900346930702"}}},"outputs":[],"source":["model = ONEArchitecture().to(device)\n","optimizer = optim.Adam(model.parameters(), lr=0.0001)\n","fisher_dict = {}\n","optpar_dict = {}\n","ewc_lambda = 0.4\n","batch_size=256"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["5c807d29c2194eb98cf2e73e924e952c","257a7cde57d34074a4d5ffa7b471d985","8a2ac70b14c34f77abfa0329a0b2858e","7473963b7ea341bc9a86a0977c124338","c8b3dcdddba34dd198ff4094cdb95a6b","d4fb71e225754bd6ae438f26e2741ef0","772bda69f40b459ca2e31ddc720b7dd8","0f77661a301246cfa5fbe087450bac1b","ade2b7e46fda4a0b973f50f2ec041195","03a3b53c8b8c4bf1aa0c3cfb4d14acb1","bec810c0b3084424be73783f01edc891","5c92e3bdba2d4e5da04731a95a8b367c","755cec9a6ced40ba8eb48ebb9ee94dcc","bf5dbb51a5b549f19c17097257276a15","959159a6b2014b108af83e50dd005499","71e6ae5fadc0415ab9ae820410cfa549","1ab230b3fda247b7a266d4925e1b52e7","977b125ba8024f17a6927e7b4af3ef62","16a68f8396c34dc1a4adc7ec211185f9","05e5f9ce1a814c26bf693fa45434c73f","b4b7d9ff34644c488c4328a595f807d4","165e40b54c4a441eaec14d548262792b","11d094d709554f1584fc30666675560b","440eed639dac4a63af9637b1da7d2960","f1f0bbc1f1794ab487d3adb38884ab75","ed6cee88fe824460ae1d7536a87438dd","86a0fe4aa5324f39aa1251bd96cd0623","04a205f2128f429fbf2bb5a00136cd67","1954d9335cf7488a9c5d658eddcabe2e","a1620904efdd42b9a00fccc43bbcb594","768b51c84de84387a70e0ce9cda0eb5e","de4c468abc994ca29ce0732eec3d3fa3","62a03d85ce9845eba8bc0f005eacff8a","4b864985aec74e1fbe4e7b611ab0d29f","2d654a9dfdf84da99d8abe79136ed226","6efb5602cec04c2691dc4c3de2fb4f0e","99b141a0064f4c028ddb44b0842d935b","640304b30b3245a5b950c39a413dc112","96cb6744704b442b96669016773aa7a2","c6f1dbec02c1492b8aa8cbcb1d8bf88a","c3c559eefcb04dcc82a1d79f2395c6bf","12a4d05ced2e478e958ff2768e4a2266","2ba59fb240544069a6390ae6e55addd5","32ac579f6fec467db270e560f2b89908","77a77e9db4374b71869d071b2af8a217","4bf52292e2914556a503644edca31575","8db155e5392d427c9c35482d7ed16de5","b1bad10e9c8945258efe68171cac46db","4c8c70b165df4dd2b673b9809ef2c86b","a987d4ccb59c4fb69c7b42172c29fe82","aff5672946ac4696867699fe098b1858","633fc4bc863446bfb7862c728f4e8348","3ef47f4b2dbd4cf38e761fa674e1d160","13fbe5eecbb546fdb39909aa0921ace7","ef29ca58d14f416bb1950c3dae8876fb","8952b3a6dd5d4715930530bc8cca0301","5d3306ae1b0d45b08a150491479117a1","d28b76ecf6ec4451887b7a40a2b370be","ef7522a07a1245de8b69ba35917dc0bc","48072b132cb94b5e926358f9cf4df9dd","483b0ea02bc843aa9854fdb8c2ff5800","0be49cfc3fc04745a58e44bf3d9490ad","12cd10063fd34375b5eaf1deccd18b89","4c919eddc95c45caaf54b70b3c85f0b9","1fa263b0c4dc465d8d8681646e61241b","642b6f04e95e4fd0a7e663a5e4aac1b1"]},"id":"JYHNYblHfP_v","outputId":"a545b63e-527a-4a9b-b6cf-61a6ab9ee6b7","executionInfo":{"status":"ok","timestamp":1701762130070,"user_tz":-330,"elapsed":1094386,"user":{"displayName":"Achyuth Kasyap","userId":"12117926900346930702"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Training on task:  0\n","Training...\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/15 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c807d29c2194eb98cf2e73e924e952c"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Testing...\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c92e3bdba2d4e5da04731a95a8b367c"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Test set: Average loss: 0.0002, Accuracy: 9895/10000 (99%)\n","Precision: 0.9895, Recall: 0.9895, F1 Score: 0.9895\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Test set: Average loss: 0.0382, Accuracy: 787/10000 (8%)\n","Precision: 0.0667, Recall: 0.0787, F1 Score: 0.0418\n","\n","Test set: Average loss: 0.0277, Accuracy: 1258/10000 (13%)\n","Precision: 0.1578, Recall: 0.1258, F1 Score: 0.0843\n","\n","Avg acc:  39.800000000000004\n","Training on task:  1\n","Training...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/15 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11d094d709554f1584fc30666675560b"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Testing...\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b864985aec74e1fbe4e7b611ab0d29f"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Test set: Average loss: 0.0113, Accuracy: 6858/10000 (69%)\n","Precision: 0.7652, Recall: 0.6858, F1 Score: 0.6859\n","\n","Test set: Average loss: 0.0005, Accuracy: 9759/10000 (98%)\n","Precision: 0.9760, Recall: 0.9759, F1 Score: 0.9759\n","\n","Test set: Average loss: 0.0454, Accuracy: 980/10000 (10%)\n","Precision: 0.1671, Recall: 0.0980, F1 Score: 0.0506\n","\n","Avg acc:  58.65666666666667\n","Training on task:  2\n","Training...\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/15 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77a77e9db4374b71869d071b2af8a217"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Testing...\n"]},{"output_type":"display_data","data":{"text/plain":["0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8952b3a6dd5d4715930530bc8cca0301"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Test set: Average loss: 0.0262, Accuracy: 4579/10000 (46%)\n","Precision: 0.4992, Recall: 0.4579, F1 Score: 0.4331\n","\n","Test set: Average loss: 0.0087, Accuracy: 6691/10000 (67%)\n","Precision: 0.7403, Recall: 0.6691, F1 Score: 0.6475\n","\n","Test set: Average loss: 0.0005, Accuracy: 9747/10000 (97%)\n","Precision: 0.9750, Recall: 0.9747, F1 Score: 0.9747\n","\n","Avg acc:  70.05666666666666\n"]}],"source":["import warnings\n","warnings.filterwarnings('ignore')\n","ewc_accs = []\n","for id, task in enumerate(tasks):\n","  avg_acc = 0\n","  print(\"Training on task: \", id)\n","\n","  (x_train, t_train), _ = task\n","  print(\"Training...\")\n","  for epoch in tqdm(range(1, 16)):\n","    train_ewc(model, device, id, x_train, t_train, optimizer, epoch)\n","  on_task_update(id, x_train, t_train)\n","\n","  print(\"Testing...\")\n","  for id_test, task in tqdm(enumerate(tasks)):\n","    # print(\"Testing on task: \", id_test)\n","    try:\n","      _, (x_test, t_test) = task\n","      acc = test(model, device, x_test, t_test)\n","      avg_acc = avg_acc + acc\n","    except Exception as e:\n","      print(\"Exception on task: {}\".format(id_test))\n","      print(\"Exception: {}\".format(e))\n","\n","  print(\"Avg acc: \", avg_acc / 3)\n","  ewc_accs.append(avg_acc / 3)"]},{"cell_type":"markdown","metadata":{"id":"mQivOXMa35Wb"},"source":["# MNIST PyTorch OWN Dataset Task Division"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kfqTU4ao3_Q6"},"outputs":[],"source":["import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p25h_UG64Bb7"},"outputs":[],"source":["complete_training_data=pd.read_csv('/content/drive/MyDrive/IIIT/Thesis/Continual_Learning/digit-recognizer/train.csv')\n","complete_testing_data=pd.read_csv('/content/drive/MyDrive/IIIT/Thesis/Continual_Learning/digit-recognizer/test.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25,"status":"ok","timestamp":1701107915425,"user":{"displayName":"Achyuth Kasyap","userId":"12117926900346930702"},"user_tz":-330},"id":"Dzw4Umdi4Dp1","outputId":"c6587e25-bd58-41f5-8882-3393adc46d8f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of Samples 42000\n","Number of Pixels 784\n"]}],"source":["number_of_samples=complete_training_data.shape[0]\n","number_of_pixels=complete_training_data.shape[1]-1\n","print('Number of Samples',number_of_samples)\n","print('Number of Pixels',number_of_pixels)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3052,"status":"ok","timestamp":1701107918463,"user":{"displayName":"Achyuth Kasyap","userId":"12117926900346930702"},"user_tz":-330},"id":"MbL1Pp0U4GXY","outputId":"1d07bd2e-a727-4860-bce6-9089d73c503f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape of the Task 1 dataset (21416, 786)\n"]}],"source":["task1_data=pd.read_csv('/content/drive/MyDrive/IIIT/Thesis/Continual_Learning/digit-recognizer/Task1_data.csv')\n","print('Shape of the Task 1 dataset',task1_data.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3526,"status":"ok","timestamp":1701107921977,"user":{"displayName":"Achyuth Kasyap","userId":"12117926900346930702"},"user_tz":-330},"id":"j7OfLtZQ4G2r","outputId":"71ae5316-f474-410a-fb85-e1c4340ca97d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape of the Task 2 dataset (12333, 786)\n"]}],"source":["task2_data=pd.read_csv('/content/drive/MyDrive/IIIT/Thesis/Continual_Learning/digit-recognizer/Task2_data.csv')\n","print('Shape of the Task 2 dataset',task2_data.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3015,"status":"ok","timestamp":1701107924955,"user":{"displayName":"Achyuth Kasyap","userId":"12117926900346930702"},"user_tz":-330},"id":"PTXrwO094I51","outputId":"2a6790d9-4444-48bc-f653-6a1cb5b0ae4c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape of the Task 3 dataset (8251, 786)\n"]}],"source":["task3_data=pd.read_csv('/content/drive/MyDrive/IIIT/Thesis/Continual_Learning/digit-recognizer/Task3_data.csv')\n","print('Shape of the Task 3 dataset',task3_data.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":49,"status":"ok","timestamp":1701107924956,"user":{"displayName":"Achyuth Kasyap","userId":"12117926900346930702"},"user_tz":-330},"id":"tLaoipyb4M7G","outputId":"7e1afc73-8230-45c1-9909-f8250097d3ac"},"outputs":[{"name":"stdout","output_type":"stream","text":["[0 1 2 3 4]\n","(19274, 784)\n","(2142, 784)\n"]}],"source":["#Splitting the training and test dataset shape\n","#Dropping the label\n","task1_label=task1_data['label']\n","print(task1_label.unique())\n","task1_data=task1_data.drop('label',axis=1)\n","task1_data=task1_data.drop('Unnamed: 0',axis=1)\n","X_train_task1,X_test_task1,Y_train_task1,Y_test_task1 = train_test_split(task1_data,task1_label,random_state=421212, test_size=0.1,shuffle=True)\n","print(X_train_task1.shape)\n","print(X_test_task1.shape)\n","X_train_task1=np.asarray(X_train_task1)\n","Y_train_task1=np.asarray(Y_train_task1)\n","X_test_task1=np.asarray(X_test_task1)\n","Y_test_task1=np.asarray(Y_test_task1)\n","X_train_task1 = np.asarray(torch.tensor(X_train_task1, dtype=torch.float32))\n","Y_train_task1 = np.asarray(torch.tensor(Y_train_task1, dtype=torch.float32))\n","X_test_task1 = np.asarray(torch.tensor(X_test_task1, dtype=torch.float32))\n","Y_test_task1 = np.asarray(torch.tensor(Y_test_task1, dtype=torch.float32))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":41,"status":"ok","timestamp":1701107924956,"user":{"displayName":"Achyuth Kasyap","userId":"12117926900346930702"},"user_tz":-330},"id":"AtMiTkwL4PSI","outputId":"194c9c37-6930-4e3d-b5fa-6d056064de85"},"outputs":[{"name":"stdout","output_type":"stream","text":["[7 6 5]\n","(11099, 784)\n","(1234, 784)\n"]}],"source":["#Splitting the training and test dataset shape\n","#Dropping the label\n","task2_label=task2_data['label']\n","print(task2_label.unique())\n","task2_data=task2_data.drop('label',axis=1)\n","task2_data=task2_data.drop('Unnamed: 0',axis=1)\n","X_train_task2,X_test_task2,Y_train_task2,Y_test_task2 = train_test_split(task2_data,task2_label,random_state=421212, test_size=0.1,shuffle=True)\n","print(X_train_task2.shape)\n","print(X_test_task2.shape)\n","\n","X_train_task2=np.asarray(X_train_task2)\n","Y_train_task2=np.asarray(Y_train_task2)\n","X_test_task2=np.asarray(X_test_task2)\n","Y_test_task2=np.asarray(Y_test_task2)\n","X_train_task2 = np.asarray(torch.tensor(X_train_task2, dtype=torch.float32))\n","Y_train_task2 = np.asarray(torch.tensor(Y_train_task2, dtype=torch.float32))\n","X_test_task2 = np.asarray(torch.tensor(X_test_task2, dtype=torch.float32))\n","Y_test_task2 = np.asarray(torch.tensor(Y_test_task2, dtype=torch.float32))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1237,"status":"ok","timestamp":1701107926160,"user":{"displayName":"Achyuth Kasyap","userId":"12117926900346930702"},"user_tz":-330},"id":"I-TgJPF-4R4t","outputId":"1166d1b5-87b2-44da-afb9-288d1d63eab9"},"outputs":[{"name":"stdout","output_type":"stream","text":["[8 9]\n","(7425, 784)\n","(826, 784)\n"]}],"source":["#Splitting the training and test dataset shape\n","#Dropping the label\n","task3_label=task3_data['label']\n","print(task3_label.unique())\n","task3_data=task3_data.drop('label',axis=1)\n","task3_data=task3_data.drop('Unnamed: 0',axis=1)\n","X_train_task3,X_test_task3,Y_train_task3,Y_test_task3 = train_test_split(task3_data,task3_label,random_state=421212, test_size=0.1,shuffle=True)\n","print(X_train_task3.shape)\n","print(X_test_task3.shape)\n","\n","X_train_task3=np.asarray(X_train_task3)\n","Y_train_task3=np.asarray(Y_train_task3)\n","X_test_task3=np.asarray(X_test_task3)\n","Y_test_task3=np.asarray(Y_test_task3)\n","X_train_task3 = np.asarray(torch.tensor(X_train_task3, dtype=torch.float32))\n","Y_train_task3 = np.asarray(torch.tensor(Y_train_task3, dtype=torch.float32))\n","X_test_task3 = np.asarray(torch.tensor(X_test_task3, dtype=torch.float32))\n","Y_test_task3 = np.asarray(torch.tensor(Y_test_task3, dtype=torch.float32))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IZ-yDkTO4Uh3"},"outputs":[],"source":["# task 1\n","task_1 = [(X_train_task1, Y_train_task1), (X_test_task1, Y_test_task1)]\n","\n","# task 2\n","task_2 = [(X_train_task2, Y_train_task2), (X_test_task2, Y_test_task2)]\n","\n","# task 3\n","task_3 = [(X_train_task3, Y_train_task3), (X_test_task3, Y_test_task3)]\n","\n","# task list\n","tasks = [task_1, task_2, task_3]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7kOKNOX54aBE"},"outputs":[],"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class ClassificationModel(nn.Module):\n","    def __init__(self, number_of_classes):\n","        super(ClassificationModel, self).__init__()\n","        self.linear1 = nn.Linear(784, 390)\n","        self.linear2 = nn.Linear(390, 190)\n","        self.linear3 = nn.Linear(190, 95)\n","        self.linear4 = nn.Linear(95, 45)\n","        self.linear5 = nn.Linear(45, 20)\n","        self.linear6 = nn.Linear(20, number_of_classes)\n","        self.dropout = nn.Dropout(0.5)  # Adding Dropout\n","\n","    def forward(self, x):\n","        x = F.relu(self.linear1(x))  # Applying Batch Normalization before activation\n","        x = F.relu(self.dropout(x))\n","        x = F.relu(self.linear2(x))\n","        x = F.relu(self.dropout(x))\n","        x = F.relu(self.linear3(x))\n","        x = F.relu(self.dropout(x))\n","        x = F.relu(self.linear4(x))\n","        x = F.relu(self.linear5(x))\n","        x = self.linear6(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XVcxVcWX4cs0"},"outputs":[],"source":["# switch to False to use CPU\n","use_cuda = True\n","\n","use_cuda = use_cuda and torch.cuda.is_available()\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\");\n","torch.manual_seed(1);"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MCum2igO4fBZ"},"outputs":[],"source":["model = ClassificationModel(10).to(device)\n","optimizer = optim.Adam(model.parameters(), lr=0.00001)\n","fisher_dict = {}\n","optpar_dict = {}\n","ewc_lambda = 10**6\n","batch_size=4"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oIyBNHI4z9Ux"},"outputs":[],"source":["from sklearn.metrics import precision_score, recall_score, f1_score\n","\n","def on_task_update(task_id, x_mem, t_mem):\n","\n","  model.train()\n","  fisher_dict[task_id] = {}\n","  optpar_dict[task_id] = {}\n","  count=0\n","  for name, param in model.named_parameters():\n","    fisher_dict[task_id][name] = param.data*0.0\n","  for start in range(0, len(t_mem)-1, batch_size):\n","      optimizer.zero_grad()\n","      count+=1\n","      # print(len(t_mem),len(x_mem))\n","      end = start + batch_size\n","      x, y = torch.from_numpy(x_mem[start:end]), torch.from_numpy(t_mem[start:end]).long()\n","      x, y = x.to(device), y.to(device)\n","      output = model(x)\n","      loss = F.cross_entropy(output, y)\n","      loss.backward()\n","      # gradients accumulated can be used to calculate fisher\n","      for name, param in model.named_parameters():\n","        fisher_dict[task_id][name] += param.grad.data.clone().pow(2)\n","  for name, param in model.named_parameters():\n","        optpar_dict[task_id][name] = param.data.clone()\n","        fisher_dict[task_id][name] = fisher_dict[task_id][name]/count\n","\n","def train_ewc(model, device, task_id, x_train, t_train, optimizer, epoch):\n","    model.train()\n","\n","    for start in range(0, len(t_train)-1, batch_size):\n","        end = start + batch_size\n","        x, y = torch.from_numpy(x_train[start:end]), torch.from_numpy(t_train[start:end]).long()\n","        x, y = x.to(device), y.to(device)\n","\n","        optimizer.zero_grad()\n","\n","        output = model(x)\n","        loss = F.cross_entropy(output, y)\n","\n","        ### magic here! :-)\n","        for task in range(task_id):\n","            for name, param in model.named_parameters():\n","                fisher = fisher_dict[task][name]\n","                optpar = optpar_dict[task][name]\n","                loss += (fisher * (optpar - param).pow(2)).sum() * ewc_lambda\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","    # After each epoch, evaluate and print metrics\n","    train_metrics = evaluate_metrics(model, device, x_train, t_train)\n","    # print(f'Train Epoch: {epoch}\\tLoss: {loss.item():.6f}\\tPrecision: {train_metrics[\"precision\"]:.4f}\\tRecall: {train_metrics[\"recall\"]:.4f}\\tF1 Score: {train_metrics[\"f1\"]:.4f}')\n","\n","def evaluate_metrics(model, device, x_data, t_data):\n","    model.eval()\n","    all_preds = []\n","    all_labels = []\n","\n","    for start in range(0, len(t_data)-1, batch_size):\n","        end = start + batch_size\n","        with torch.no_grad():\n","            x, y = torch.from_numpy(x_data[start:end]), torch.from_numpy(t_data[start:end]).long()\n","            x, y = x.to(device), y.to(device)\n","            output = model(x)\n","\n","            # Convert predictions to numpy arrays\n","            preds = output.argmax(dim=1).cpu().numpy()\n","            labels = y.cpu().numpy()\n","\n","            all_preds.extend(preds)\n","            all_labels.extend(labels)\n","\n","    # Calculate metrics\n","    precision = precision_score(all_labels, all_preds, average='weighted')\n","    recall = recall_score(all_labels, all_preds, average='weighted')\n","    f1 = f1_score(all_labels, all_preds, average='weighted')\n","\n","    return {'precision': precision, 'recall': recall, 'f1': f1}\n","\n","def train(model, device, x_train, t_train, optimizer, epoch):\n","    model.train()\n","\n","    for start in range(0, len(t_train)-1, batch_size):\n","      end = start + batch_size\n","      x, y = torch.from_numpy(x_train[start:end]), torch.from_numpy(t_train[start:end]).long()\n","      x, y = x.to(device), y.to(device)\n","\n","      optimizer.zero_grad()\n","\n","      output = model(x)\n","      loss = F.cross_entropy(output, y)\n","      loss.backward()\n","      optimizer.step()\n","      #print(loss.item())\n","    # print('Train Epoch: {} \\tLoss: {:.6f}'.format(epoch, loss.item()))\n","\n","def test(model, device, x_test, t_test):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    all_preds = []\n","    all_labels = []\n","\n","    for start in range(0, len(t_test)-1, batch_size):\n","        end = start + batch_size\n","        with torch.no_grad():\n","            x, y = torch.from_numpy(x_test[start:end]), torch.from_numpy(t_test[start:end]).long()\n","            x, y = x.to(device), y.to(device)\n","            output = model(x)\n","            test_loss += F.cross_entropy(output, y).item()  # sum up batch loss\n","            pred = output.max(1, keepdim=True)[1]  # get the index of the max logit\n","            correct += pred.eq(y.view_as(pred)).sum().item()\n","\n","            # Convert predictions to numpy arrays\n","            preds = pred.cpu().numpy()\n","            labels = y.cpu().numpy()\n","\n","            all_preds.extend(preds)\n","            all_labels.extend(labels)\n","\n","    test_loss /= len(t_test)\n","\n","    # Calculate metrics\n","    precision = precision_score(all_labels, all_preds, average='weighted')\n","    recall = recall_score(all_labels, all_preds, average='weighted')\n","    f1 = f1_score(all_labels, all_preds, average='weighted')\n","\n","    print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n","        test_loss, correct, len(t_test), 100. * correct / len(t_test)))\n","    print('Precision: {:.4f}, Recall: {:.4f}, F1 Score: {:.4f}\\n'.format(precision, recall, f1))\n","\n","    return 100. * correct / len(t_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"1wSYdM9bn4iw","outputId":"1588985f-28d4-4fbc-8a23-71e5d2b78924"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training on task:  0\n","Testing on task:  0\n","Test set: Average loss: 0.0267, Accuracy: 2084/2142 (97%)\n","Precision: 0.9730, Recall: 0.9729, F1 Score: 0.9729\n","\n","Testing on task:  1\n","Test set: Average loss: 3.1087, Accuracy: 0/1234 (0%)\n","Precision: 0.0000, Recall: 0.0000, F1 Score: 0.0000\n","\n","Testing on task:  2\n","Test set: Average loss: 3.5799, Accuracy: 0/826 (0%)\n","Precision: 0.0000, Recall: 0.0000, F1 Score: 0.0000\n","\n","Avg acc:  32.4307500778089\n","Training on task:  1\n","Testing on task:  0\n","Test set: Average loss: 0.2510, Accuracy: 1573/2142 (73%)\n","Precision: 0.9947, Recall: 0.7344, F1 Score: 0.8314\n","\n","Testing on task:  1\n","Test set: Average loss: 0.4080, Accuracy: 716/1234 (58%)\n","Precision: 0.6645, Recall: 0.5802, F1 Score: 0.5756\n","\n","Testing on task:  2\n","Test set: Average loss: 1.1783, Accuracy: 0/826 (0%)\n","Precision: 0.0000, Recall: 0.0000, F1 Score: 0.0000\n","\n","Avg acc:  43.81957717356707\n","Training on task:  2\n","Testing on task:  0\n","Test set: Average loss: 0.2550, Accuracy: 1575/2142 (74%)\n","Precision: 0.9948, Recall: 0.7353, F1 Score: 0.8322\n","\n","Testing on task:  1\n","Test set: Average loss: 0.4184, Accuracy: 716/1234 (58%)\n","Precision: 0.6652, Recall: 0.5802, F1 Score: 0.5760\n","\n","Testing on task:  2\n","Test set: Average loss: 0.8893, Accuracy: 0/826 (0%)\n","Precision: 0.0000, Recall: 0.0000, F1 Score: 0.0000\n","\n","Avg acc:  43.850700734102396\n"]}],"source":["import warnings\n","warnings.filterwarnings('ignore')\n","ewc_accs = []\n","for id, task in enumerate(tasks):\n","  avg_acc = 0\n","  print(\"Training on task: \", id)\n","\n","  (x_train, t_train), _ = task\n","\n","  for epoch in range(1, 11):\n","    train_ewc(model, device, id, x_train, t_train, optimizer, epoch)\n","  on_task_update(id, x_train, t_train)\n","\n","  for id_test, task in enumerate(tasks):\n","    print(\"Testing on task: \", id_test)\n","    _, (x_test, t_test) = task\n","    acc = test(model, device, x_test, t_test)\n","    avg_acc = avg_acc + acc\n","\n","  print(\"Avg acc: \", avg_acc / 3)\n","  ewc_accs.append(avg_acc / 3)"]},{"cell_type":"markdown","source":["# UNET Architecture"],"metadata":{"id":"rDy24ZgCmn-x"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zq91gXQ27oX4"},"outputs":[],"source":["import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","source":["complete_training_data=pd.read_csv('/content/drive/MyDrive/IIIT/Thesis/Continual_Learning/digit-recognizer/train.csv')\n","complete_testing_data=pd.read_csv('/content/drive/MyDrive/IIIT/Thesis/Continual_Learning/digit-recognizer/test.csv')"],"metadata":{"id":"5YslcsozmrNp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["number_of_samples=complete_training_data.shape[0]\n","number_of_pixels=complete_training_data.shape[1]-1\n","print('Number of Samples',number_of_samples)\n","print('Number of Pixels',number_of_pixels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UDC1bWzHmsmQ","executionInfo":{"status":"ok","timestamp":1701710131148,"user_tz":-330,"elapsed":17,"user":{"displayName":"Achyuth Kasyap","userId":"12117926900346930702"}},"outputId":"a50e0149-15bb-4906-a544-cc4655a7bef6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of Samples 42000\n","Number of Pixels 784\n"]}]},{"cell_type":"code","source":["task1_data=pd.read_csv('/content/drive/MyDrive/IIIT/Thesis/Continual_Learning/digit-recognizer/Task1_data.csv')\n","print('Shape of the Task 1 dataset',task1_data.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ST7Gwvfymuby","executionInfo":{"status":"ok","timestamp":1701710132392,"user_tz":-330,"elapsed":1255,"user":{"displayName":"Achyuth Kasyap","userId":"12117926900346930702"}},"outputId":"afa81ee5-c209-4854-c756-b7a71133a269"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of the Task 1 dataset (21416, 786)\n"]}]},{"cell_type":"code","source":["task2_data=pd.read_csv('/content/drive/MyDrive/IIIT/Thesis/Continual_Learning/digit-recognizer/Task2_data.csv')\n","print('Shape of the Task 2 dataset',task2_data.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x2cmrzJDmwhj","executionInfo":{"status":"ok","timestamp":1701710132393,"user_tz":-330,"elapsed":13,"user":{"displayName":"Achyuth Kasyap","userId":"12117926900346930702"}},"outputId":"eb4c79db-7d89-45b0-efcb-c2524b5f3e72"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of the Task 2 dataset (12333, 786)\n"]}]},{"cell_type":"code","source":["task3_data=pd.read_csv('/content/drive/MyDrive/IIIT/Thesis/Continual_Learning/digit-recognizer/Task3_data.csv')\n","print('Shape of the Task 3 dataset',task3_data.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I5kHDSQymwj8","executionInfo":{"status":"ok","timestamp":1701710133327,"user_tz":-330,"elapsed":941,"user":{"displayName":"Achyuth Kasyap","userId":"12117926900346930702"}},"outputId":"a6f713ef-d1dd-43df-b3f6-5bae460dd86e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of the Task 3 dataset (8251, 786)\n"]}]},{"cell_type":"code","source":["#Splitting the training and test dataset shape\n","#Dropping the label\n","task1_label=task1_data['label']\n","print(task1_label.unique())\n","task1_data=task1_data.drop('label',axis=1)\n","task1_data=task1_data.drop('Unnamed: 0',axis=1)\n","X_train_task1,X_test_task1,Y_train_task1,Y_test_task1 = train_test_split(task1_data,task1_label,random_state=421212, test_size=0.1,shuffle=True)\n","print(X_train_task1.shape)\n","print(X_test_task1.shape)\n","X_train_task1=np.asarray(X_train_task1)\n","Y_train_task1=np.asarray(Y_train_task1)\n","X_test_task1=np.asarray(X_test_task1)\n","Y_test_task1=np.asarray(Y_test_task1)\n","X_train_task1 = np.asarray(torch.tensor(X_train_task1, dtype=torch.float32))\n","Y_train_task1 = np.asarray(torch.tensor(Y_train_task1, dtype=torch.float32))\n","X_test_task1 = np.asarray(torch.tensor(X_test_task1, dtype=torch.float32))\n","Y_test_task1 = np.asarray(torch.tensor(Y_test_task1, dtype=torch.float32))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C9OcsfiLmwma","executionInfo":{"status":"ok","timestamp":1701710133328,"user_tz":-330,"elapsed":64,"user":{"displayName":"Achyuth Kasyap","userId":"12117926900346930702"}},"outputId":"b2e18b80-b012-47a6-c5dc-ce9f90568e0c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[0 1 2 3 4]\n","(19274, 784)\n","(2142, 784)\n"]}]},{"cell_type":"code","source":["#Splitting the training and test dataset shape\n","#Dropping the label\n","task2_label=task2_data['label']\n","print(task2_label.unique())\n","task2_data=task2_data.drop('label',axis=1)\n","task2_data=task2_data.drop('Unnamed: 0',axis=1)\n","X_train_task2,X_test_task2,Y_train_task2,Y_test_task2 = train_test_split(task2_data,task2_label,random_state=421212, test_size=0.1,shuffle=True)\n","print(X_train_task2.shape)\n","print(X_test_task2.shape)\n","\n","X_train_task2=np.asarray(X_train_task2)\n","Y_train_task2=np.asarray(Y_train_task2)\n","X_test_task2=np.asarray(X_test_task2)\n","Y_test_task2=np.asarray(Y_test_task2)\n","X_train_task2 = np.asarray(torch.tensor(X_train_task2, dtype=torch.float32))\n","Y_train_task2 = np.asarray(torch.tensor(Y_train_task2, dtype=torch.float32))\n","X_test_task2 = np.asarray(torch.tensor(X_test_task2, dtype=torch.float32))\n","Y_test_task2 = np.asarray(torch.tensor(Y_test_task2, dtype=torch.float32))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jEyWvfikmwor","executionInfo":{"status":"ok","timestamp":1701710133329,"user_tz":-330,"elapsed":52,"user":{"displayName":"Achyuth Kasyap","userId":"12117926900346930702"}},"outputId":"1adab5dd-269b-42b1-b10a-3623b2815622"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[7 6 5]\n","(11099, 784)\n","(1234, 784)\n"]}]},{"cell_type":"code","source":["#Splitting the training and test dataset shape\n","#Dropping the label\n","task3_label=task3_data['label']\n","print(task3_label.unique())\n","task3_data=task3_data.drop('label',axis=1)\n","task3_data=task3_data.drop('Unnamed: 0',axis=1)\n","X_train_task3,X_test_task3,Y_train_task3,Y_test_task3 = train_test_split(task3_data,task3_label,random_state=421212, test_size=0.1,shuffle=True)\n","print(X_train_task3.shape)\n","print(X_test_task3.shape)\n","\n","X_train_task3=np.asarray(X_train_task3)\n","Y_train_task3=np.asarray(Y_train_task3)\n","X_test_task3=np.asarray(X_test_task3)\n","Y_test_task3=np.asarray(Y_test_task3)\n","X_train_task3 = np.asarray(torch.tensor(X_train_task3, dtype=torch.float32))\n","Y_train_task3 = np.asarray(torch.tensor(Y_train_task3, dtype=torch.float32))\n","X_test_task3 = np.asarray(torch.tensor(X_test_task3, dtype=torch.float32))\n","Y_test_task3 = np.asarray(torch.tensor(Y_test_task3, dtype=torch.float32))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uXrblkZom5eK","executionInfo":{"status":"ok","timestamp":1701710133330,"user_tz":-330,"elapsed":43,"user":{"displayName":"Achyuth Kasyap","userId":"12117926900346930702"}},"outputId":"b43ff895-f225-459b-e32a-1834da51e83a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[8 9]\n","(7425, 784)\n","(826, 784)\n"]}]},{"cell_type":"code","source":["# task 1\n","task_1 = [(X_train_task1, Y_train_task1), (X_test_task1, Y_test_task1)]\n","\n","# task 2\n","task_2 = [(X_train_task2, Y_train_task2), (X_test_task2, Y_test_task2)]\n","\n","# task 3\n","task_3 = [(X_train_task3, Y_train_task3), (X_test_task3, Y_test_task3)]\n","\n","# task list\n","tasks = [task_1, task_2, task_3]"],"metadata":{"id":"WHLExm00m7J6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class UNet(nn.Module):\n","    def __init__(self, input_size, output_size):\n","        super(UNet, self).__init__()\n","\n","        # Encoder layers\n","        self.enc1 = nn.Linear(input_size, 256)\n","        self.enc2 = nn.Linear(256, 128)\n","        self.enc3 = nn.Linear(128, 64)\n","        self.enc4 = nn.Linear(64, 32)\n","        self.enc5 = nn.Linear(32, 16)\n","\n","        # Decoder layers\n","        self.dec5 = nn.Linear(16, 32)\n","        self.dec4 = nn.Linear(32, 64)\n","        self.dec3 = nn.Linear(64, 128)\n","        self.dec2 = nn.Linear(128, 256)\n","        self.dec1 = nn.Linear(256, output_size)\n","\n","    def forward(self, x):\n","        # Encoding\n","        x1 = F.relu(self.enc1(x))\n","        x2 = F.relu(self.enc2(x1))\n","        x3 = F.relu(self.enc3(x2))\n","        x4 = F.relu(self.enc4(x3))\n","        x5 = F.relu(self.enc5(x4))\n","\n","        # Decoding with skip connections\n","        x_dec5 = F.relu(self.dec5(x5))\n","        x_dec4 = F.relu(self.dec4(x_dec5))\n","        x_dec3 = F.relu(self.dec3(x_dec4))\n","        x_dec2 = F.relu(self.dec2(x_dec3))\n","        x_out = self.dec1(x_dec2)\n","\n","        return x_out\n","\n","# Example usage\n","input_size = 784\n","output_size = 10\n","\n","model = UNet(input_size, output_size)"],"metadata":{"id":"6DXiut_DnIJ8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# switch to False to use CPU\n","use_cuda = True\n","\n","use_cuda = use_cuda and torch.cuda.is_available()\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\");\n","torch.manual_seed(1);"],"metadata":{"id":"8IynuSd-nIrO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["optimizer = optim.Adam(model.parameters(), lr=0.00001)\n","fisher_dict = {}\n","optpar_dict = {}\n","ewc_lambda = 10**6\n","batch_size=256"],"metadata":{"id":"XqHkkpMonUzm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import precision_score, recall_score, f1_score\n","\n","def on_task_update(task_id, x_mem, t_mem):\n","\n","  model.train()\n","  fisher_dict[task_id] = {}\n","  optpar_dict[task_id] = {}\n","  count=0\n","  for name, param in model.named_parameters():\n","    fisher_dict[task_id][name] = param.data*0.0\n","  for start in range(0, len(t_mem)-1, batch_size):\n","      optimizer.zero_grad()\n","      count+=1\n","      # print(len(t_mem),len(x_mem))\n","      end = start + batch_size\n","      x, y = torch.from_numpy(x_mem[start:end]), torch.from_numpy(t_mem[start:end]).long()\n","      x, y = x.to(device), y.to(device)\n","      output = model(x)\n","      loss = F.cross_entropy(output, y)\n","      loss.backward()\n","      # gradients accumulated can be used to calculate fisher\n","      for name, param in model.named_parameters():\n","        fisher_dict[task_id][name] += param.grad.data.clone().pow(2)\n","  for name, param in model.named_parameters():\n","        optpar_dict[task_id][name] = param.data.clone()\n","        fisher_dict[task_id][name] = fisher_dict[task_id][name]/count\n","\n","def train_ewc(model, device, task_id, x_train, t_train, optimizer, epoch):\n","    model.train()\n","\n","    for start in range(0, len(t_train)-1, batch_size):\n","        end = start + batch_size\n","        x, y = torch.from_numpy(x_train[start:end]), torch.from_numpy(t_train[start:end]).long()\n","        x, y = x.to(device), y.to(device)\n","\n","        optimizer.zero_grad()\n","\n","        output = model(x)\n","        loss = F.cross_entropy(output, y)\n","\n","        ### magic here! :-)\n","        for task in range(task_id):\n","            for name, param in model.named_parameters():\n","                fisher = fisher_dict[task][name]\n","                optpar = optpar_dict[task][name]\n","                loss += (fisher * (optpar - param).pow(2)).sum() * ewc_lambda\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","    # After each epoch, evaluate and print metrics\n","    train_metrics = evaluate_metrics(model, device, x_train, t_train)\n","    # print(f'Train Epoch: {epoch}\\tLoss: {loss.item():.6f}\\tPrecision: {train_metrics[\"precision\"]:.4f}\\tRecall: {train_metrics[\"recall\"]:.4f}\\tF1 Score: {train_metrics[\"f1\"]:.4f}')\n","\n","def evaluate_metrics(model, device, x_data, t_data):\n","    model.eval()\n","    all_preds = []\n","    all_labels = []\n","\n","    for start in range(0, len(t_data)-1, batch_size):\n","        end = start + batch_size\n","        with torch.no_grad():\n","            x, y = torch.from_numpy(x_data[start:end]), torch.from_numpy(t_data[start:end]).long()\n","            x, y = x.to(device), y.to(device)\n","            output = model(x)\n","\n","            # Convert predictions to numpy arrays\n","            preds = output.argmax(dim=1).cpu().numpy()\n","            labels = y.cpu().numpy()\n","\n","            all_preds.extend(preds)\n","            all_labels.extend(labels)\n","\n","    # Calculate metrics\n","    precision = precision_score(all_labels, all_preds, average='weighted')\n","    recall = recall_score(all_labels, all_preds, average='weighted')\n","    f1 = f1_score(all_labels, all_preds, average='weighted')\n","\n","    return {'precision': precision, 'recall': recall, 'f1': f1}\n","\n","def train(model, device, x_train, t_train, optimizer, epoch):\n","    model.train()\n","\n","    for start in range(0, len(t_train)-1, batch_size):\n","      end = start + batch_size\n","      x, y = torch.from_numpy(x_train[start:end]), torch.from_numpy(t_train[start:end]).long()\n","      x, y = x.to(device), y.to(device)\n","\n","      optimizer.zero_grad()\n","\n","      output = model(x)\n","      loss = F.cross_entropy(output, y)\n","      loss.backward()\n","      optimizer.step()\n","      #print(loss.item())\n","    # print('Train Epoch: {} \\tLoss: {:.6f}'.format(epoch, loss.item()))\n","\n","def test(model, device, x_test, t_test):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    all_preds = []\n","    all_labels = []\n","\n","    for start in range(0, len(t_test)-1, batch_size):\n","        end = start + batch_size\n","        with torch.no_grad():\n","            x, y = torch.from_numpy(x_test[start:end]), torch.from_numpy(t_test[start:end]).long()\n","            x, y = x.to(device), y.to(device)\n","            output = model(x)\n","            test_loss += F.cross_entropy(output, y).item()  # sum up batch loss\n","            pred = output.max(1, keepdim=True)[1]  # get the index of the max logit\n","            correct += pred.eq(y.view_as(pred)).sum().item()\n","\n","            # Convert predictions to numpy arrays\n","            preds = pred.cpu().numpy()\n","            labels = y.cpu().numpy()\n","\n","            all_preds.extend(preds)\n","            all_labels.extend(labels)\n","\n","    test_loss /= len(t_test)\n","\n","    # Calculate metrics\n","    precision = precision_score(all_labels, all_preds, average='weighted')\n","    recall = recall_score(all_labels, all_preds, average='weighted')\n","    f1 = f1_score(all_labels, all_preds, average='weighted')\n","\n","    print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n","        test_loss, correct, len(t_test), 100. * correct / len(t_test)))\n","    print('Precision: {:.4f}, Recall: {:.4f}, F1 Score: {:.4f}\\n'.format(precision, recall, f1))\n","\n","    return 100. * correct / len(t_test)"],"metadata":{"id":"BvCzclRtnU2G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import warnings\n","warnings.filterwarnings('ignore')\n","ewc_accs = []\n","for id, task in enumerate(tasks):\n","  avg_acc = 0\n","  print(\"Training on task: \", id)\n","\n","  (x_train, t_train), _ = task\n","\n","  for epoch in range(1, 11):\n","    train_ewc(model, device, id, x_train, t_train, optimizer, epoch)\n","  on_task_update(id, x_train, t_train)\n","\n","  for id_test, task in enumerate(tasks):\n","    print(\"Testing on task: \", id_test)\n","    _, (x_test, t_test) = task\n","    acc = test(model, device, x_test, t_test)\n","    avg_acc = avg_acc + acc\n","\n","  print(\"Avg acc: \", avg_acc / 3)\n","  ewc_accs.append(avg_acc / 3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bDLMQxAinZ1v","executionInfo":{"status":"ok","timestamp":1701710170969,"user_tz":-330,"elapsed":36628,"user":{"displayName":"Achyuth Kasyap","userId":"12117926900346930702"}},"outputId":"a0780f45-00a9-43e0-af5e-c2645ee15924"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training on task:  0\n","Testing on task:  0\n","Test set: Average loss: 0.0030, Accuracy: 1978/2142 (92%)\n","Precision: 0.9263, Recall: 0.9234, F1 Score: 0.9247\n","\n","Testing on task:  1\n","Test set: Average loss: 0.1833, Accuracy: 21/1234 (2%)\n","Precision: 0.2839, Recall: 0.0170, F1 Score: 0.0321\n","\n","Testing on task:  2\n","Test set: Average loss: 0.2763, Accuracy: 2/826 (0%)\n","Precision: 0.1418, Recall: 0.0024, F1 Score: 0.0048\n","\n","Avg acc:  31.429172559670857\n","Training on task:  1\n","Testing on task:  0\n","Test set: Average loss: 0.0194, Accuracy: 1289/2142 (60%)\n","Precision: 0.9606, Recall: 0.6018, F1 Score: 0.7316\n","\n","Testing on task:  1\n","Test set: Average loss: 0.0148, Accuracy: 788/1234 (64%)\n","Precision: 0.7755, Recall: 0.6386, F1 Score: 0.6986\n","\n","Testing on task:  2\n","Test set: Average loss: 0.2870, Accuracy: 1/826 (0%)\n","Precision: 0.1241, Recall: 0.0012, F1 Score: 0.0024\n","\n","Avg acc:  41.38528135419148\n","Training on task:  2\n","Testing on task:  0\n","Test set: Average loss: 0.0185, Accuracy: 1304/2142 (61%)\n","Precision: 0.9620, Recall: 0.6088, F1 Score: 0.7378\n","\n","Testing on task:  1\n","Test set: Average loss: 0.0159, Accuracy: 758/1234 (61%)\n","Precision: 0.7815, Recall: 0.6143, F1 Score: 0.6861\n","\n","Testing on task:  2\n","Test set: Average loss: 0.1242, Accuracy: 21/826 (3%)\n","Precision: 0.3871, Recall: 0.0254, F1 Score: 0.0477\n","\n","Avg acc:  41.6154377887493\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"RGEiI2sMO32b"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4","collapsed_sections":["d1y9VuJFYhZW","mQivOXMa35Wb","rDy24ZgCmn-x"],"mount_file_id":"1_xaaVcSYR-BTTEA8noFR6UvCQ9Rit9nC","authorship_tag":"ABX9TyOBwD3F1zUcRvo8pD74dR1K"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"5c807d29c2194eb98cf2e73e924e952c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_257a7cde57d34074a4d5ffa7b471d985","IPY_MODEL_8a2ac70b14c34f77abfa0329a0b2858e","IPY_MODEL_7473963b7ea341bc9a86a0977c124338"],"layout":"IPY_MODEL_c8b3dcdddba34dd198ff4094cdb95a6b"}},"257a7cde57d34074a4d5ffa7b471d985":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d4fb71e225754bd6ae438f26e2741ef0","placeholder":"​","style":"IPY_MODEL_772bda69f40b459ca2e31ddc720b7dd8","value":"100%"}},"8a2ac70b14c34f77abfa0329a0b2858e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0f77661a301246cfa5fbe087450bac1b","max":15,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ade2b7e46fda4a0b973f50f2ec041195","value":15}},"7473963b7ea341bc9a86a0977c124338":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_03a3b53c8b8c4bf1aa0c3cfb4d14acb1","placeholder":"​","style":"IPY_MODEL_bec810c0b3084424be73783f01edc891","value":" 15/15 [04:39&lt;00:00, 18.90s/it]"}},"c8b3dcdddba34dd198ff4094cdb95a6b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d4fb71e225754bd6ae438f26e2741ef0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"772bda69f40b459ca2e31ddc720b7dd8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0f77661a301246cfa5fbe087450bac1b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ade2b7e46fda4a0b973f50f2ec041195":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"03a3b53c8b8c4bf1aa0c3cfb4d14acb1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bec810c0b3084424be73783f01edc891":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5c92e3bdba2d4e5da04731a95a8b367c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_755cec9a6ced40ba8eb48ebb9ee94dcc","IPY_MODEL_bf5dbb51a5b549f19c17097257276a15","IPY_MODEL_959159a6b2014b108af83e50dd005499"],"layout":"IPY_MODEL_71e6ae5fadc0415ab9ae820410cfa549"}},"755cec9a6ced40ba8eb48ebb9ee94dcc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ab230b3fda247b7a266d4925e1b52e7","placeholder":"​","style":"IPY_MODEL_977b125ba8024f17a6927e7b4af3ef62","value":""}},"bf5dbb51a5b549f19c17097257276a15":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_16a68f8396c34dc1a4adc7ec211185f9","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_05e5f9ce1a814c26bf693fa45434c73f","value":1}},"959159a6b2014b108af83e50dd005499":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b4b7d9ff34644c488c4328a595f807d4","placeholder":"​","style":"IPY_MODEL_165e40b54c4a441eaec14d548262792b","value":" 3/? [00:02&lt;00:00,  1.14it/s]"}},"71e6ae5fadc0415ab9ae820410cfa549":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1ab230b3fda247b7a266d4925e1b52e7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"977b125ba8024f17a6927e7b4af3ef62":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"16a68f8396c34dc1a4adc7ec211185f9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"05e5f9ce1a814c26bf693fa45434c73f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b4b7d9ff34644c488c4328a595f807d4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"165e40b54c4a441eaec14d548262792b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"11d094d709554f1584fc30666675560b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_440eed639dac4a63af9637b1da7d2960","IPY_MODEL_f1f0bbc1f1794ab487d3adb38884ab75","IPY_MODEL_ed6cee88fe824460ae1d7536a87438dd"],"layout":"IPY_MODEL_86a0fe4aa5324f39aa1251bd96cd0623"}},"440eed639dac4a63af9637b1da7d2960":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_04a205f2128f429fbf2bb5a00136cd67","placeholder":"​","style":"IPY_MODEL_1954d9335cf7488a9c5d658eddcabe2e","value":"100%"}},"f1f0bbc1f1794ab487d3adb38884ab75":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a1620904efdd42b9a00fccc43bbcb594","max":15,"min":0,"orientation":"horizontal","style":"IPY_MODEL_768b51c84de84387a70e0ce9cda0eb5e","value":15}},"ed6cee88fe824460ae1d7536a87438dd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_de4c468abc994ca29ce0732eec3d3fa3","placeholder":"​","style":"IPY_MODEL_62a03d85ce9845eba8bc0f005eacff8a","value":" 15/15 [05:54&lt;00:00, 23.55s/it]"}},"86a0fe4aa5324f39aa1251bd96cd0623":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"04a205f2128f429fbf2bb5a00136cd67":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1954d9335cf7488a9c5d658eddcabe2e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a1620904efdd42b9a00fccc43bbcb594":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"768b51c84de84387a70e0ce9cda0eb5e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"de4c468abc994ca29ce0732eec3d3fa3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"62a03d85ce9845eba8bc0f005eacff8a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4b864985aec74e1fbe4e7b611ab0d29f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2d654a9dfdf84da99d8abe79136ed226","IPY_MODEL_6efb5602cec04c2691dc4c3de2fb4f0e","IPY_MODEL_99b141a0064f4c028ddb44b0842d935b"],"layout":"IPY_MODEL_640304b30b3245a5b950c39a413dc112"}},"2d654a9dfdf84da99d8abe79136ed226":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_96cb6744704b442b96669016773aa7a2","placeholder":"​","style":"IPY_MODEL_c6f1dbec02c1492b8aa8cbcb1d8bf88a","value":""}},"6efb5602cec04c2691dc4c3de2fb4f0e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c3c559eefcb04dcc82a1d79f2395c6bf","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_12a4d05ced2e478e958ff2768e4a2266","value":1}},"99b141a0064f4c028ddb44b0842d935b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2ba59fb240544069a6390ae6e55addd5","placeholder":"​","style":"IPY_MODEL_32ac579f6fec467db270e560f2b89908","value":" 3/? [00:02&lt;00:00,  1.19it/s]"}},"640304b30b3245a5b950c39a413dc112":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96cb6744704b442b96669016773aa7a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6f1dbec02c1492b8aa8cbcb1d8bf88a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c3c559eefcb04dcc82a1d79f2395c6bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"12a4d05ced2e478e958ff2768e4a2266":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2ba59fb240544069a6390ae6e55addd5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"32ac579f6fec467db270e560f2b89908":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"77a77e9db4374b71869d071b2af8a217":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4bf52292e2914556a503644edca31575","IPY_MODEL_8db155e5392d427c9c35482d7ed16de5","IPY_MODEL_b1bad10e9c8945258efe68171cac46db"],"layout":"IPY_MODEL_4c8c70b165df4dd2b673b9809ef2c86b"}},"4bf52292e2914556a503644edca31575":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a987d4ccb59c4fb69c7b42172c29fe82","placeholder":"​","style":"IPY_MODEL_aff5672946ac4696867699fe098b1858","value":"100%"}},"8db155e5392d427c9c35482d7ed16de5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_633fc4bc863446bfb7862c728f4e8348","max":15,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3ef47f4b2dbd4cf38e761fa674e1d160","value":15}},"b1bad10e9c8945258efe68171cac46db":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_13fbe5eecbb546fdb39909aa0921ace7","placeholder":"​","style":"IPY_MODEL_ef29ca58d14f416bb1950c3dae8876fb","value":" 15/15 [06:56&lt;00:00, 27.78s/it]"}},"4c8c70b165df4dd2b673b9809ef2c86b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a987d4ccb59c4fb69c7b42172c29fe82":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aff5672946ac4696867699fe098b1858":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"633fc4bc863446bfb7862c728f4e8348":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ef47f4b2dbd4cf38e761fa674e1d160":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"13fbe5eecbb546fdb39909aa0921ace7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef29ca58d14f416bb1950c3dae8876fb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8952b3a6dd5d4715930530bc8cca0301":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5d3306ae1b0d45b08a150491479117a1","IPY_MODEL_d28b76ecf6ec4451887b7a40a2b370be","IPY_MODEL_ef7522a07a1245de8b69ba35917dc0bc"],"layout":"IPY_MODEL_48072b132cb94b5e926358f9cf4df9dd"}},"5d3306ae1b0d45b08a150491479117a1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_483b0ea02bc843aa9854fdb8c2ff5800","placeholder":"​","style":"IPY_MODEL_0be49cfc3fc04745a58e44bf3d9490ad","value":""}},"d28b76ecf6ec4451887b7a40a2b370be":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_12cd10063fd34375b5eaf1deccd18b89","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4c919eddc95c45caaf54b70b3c85f0b9","value":1}},"ef7522a07a1245de8b69ba35917dc0bc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1fa263b0c4dc465d8d8681646e61241b","placeholder":"​","style":"IPY_MODEL_642b6f04e95e4fd0a7e663a5e4aac1b1","value":" 3/? [00:02&lt;00:00,  1.26it/s]"}},"48072b132cb94b5e926358f9cf4df9dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"483b0ea02bc843aa9854fdb8c2ff5800":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0be49cfc3fc04745a58e44bf3d9490ad":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"12cd10063fd34375b5eaf1deccd18b89":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"4c919eddc95c45caaf54b70b3c85f0b9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1fa263b0c4dc465d8d8681646e61241b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"642b6f04e95e4fd0a7e663a5e4aac1b1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}